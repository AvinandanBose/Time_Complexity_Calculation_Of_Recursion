<h1 align="Center">𝑻𝒊𝒎𝒆 𝑪𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝑪𝒂𝒍𝒄𝒖𝒍𝒂𝒕𝒊𝒐𝒏 𝑶𝒇 𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒐𝒏</h1>
<h1 align="Center">𝟏.𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏</h1>

<ul>
  
<h2><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins></h2>

<ul>


<h3>𝑻𝒉𝒆 𝒂𝒏𝒂𝒍𝒚𝒔𝒊𝒔 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒂𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎 𝒓𝒆𝒒𝒖𝒊𝒓𝒆𝒔 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔.𝑻𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆
𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔 𝒐𝒇 𝒕𝒉𝒂𝒕 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆.𝑯𝒆𝒓𝒆 𝒃𝒂𝒔𝒆 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 𝒐𝒓 𝒊𝒏𝒊𝒕𝒊𝒂𝒍 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 𝒐𝒓 𝒃𝒂𝒔𝒊𝒔 𝒔𝒕𝒆𝒑
𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒔 𝒔𝒂𝒎𝒆 𝒕𝒆𝒓𝒎𝒊𝒏𝒐𝒍𝒐𝒈𝒚.𝑺𝒊𝒎𝒊𝒍𝒂𝒓𝒍𝒚 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒔𝒕𝒆𝒑 𝒐𝒓 𝒑𝒓𝒆𝒄𝒆𝒅𝒊𝒏𝒈 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒍𝒔𝒐
𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒔 𝒔𝒂𝒎𝒆 𝒕𝒆𝒓𝒎𝒊𝒏𝒊𝒍𝒐𝒈𝒚.</h3>


</ul>

<h2></h2>
<h2><ins>𝑺𝒊𝒆𝒓𝒑𝒊𝒏𝒔𝒌𝒊 𝑻𝒓𝒊𝒂𝒏𝒈𝒍𝒆</ins></h2>

<ul>

![Screenshot (821)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/62b191dc-58ea-4573-8e55-4c599901b871)

<h3>𝑻𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒇𝒊𝒈𝒖𝒓𝒆 𝒔𝒉𝒐𝒘𝒔 𝒂 𝑺𝒊𝒆𝒓𝒑𝒊𝒏𝒔𝒌𝒊 𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆 , 𝒘𝒉𝒊𝒄𝒉 𝒏𝒂𝒎𝒆𝒅
𝒂𝒇𝒕𝒆𝒓 𝑾𝒂𝒄𝒍𝒂𝒘 𝑺𝒊𝒆𝒓𝒑𝒊𝒏𝒔𝒌𝒊, 𝒂 𝑷𝒐𝒍𝒊𝒔𝒉 𝒎𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒊𝒂𝒏.</h3>


<h3>𝑻𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒔𝒕𝒆𝒑𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒂𝒍𝒐𝒈𝒊𝒓𝒕𝒉𝒎 𝒕𝒐 𝒄𝒓𝒆𝒂𝒕𝒆 𝒕𝒉𝒆 𝒇𝒊𝒈𝒖𝒓𝒆:</h3>

<ul>
  
<h3>𝟏. 𝑪𝒉𝒐𝒐𝒔𝒆 𝒂𝒏𝒚 𝒃𝒐𝒖𝒏𝒅𝒆𝒅 𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆 𝒘𝒉𝒐𝒔𝒆 𝒃𝒂𝒔𝒆 𝒑𝒂𝒓𝒂𝒍𝒍𝒆𝒍
𝒕𝒐 𝒕𝒉𝒆 𝒉𝒐𝒓𝒊𝒛𝒐𝒏𝒕𝒂𝒍 𝒂𝒙𝒊𝒔.</h3>

![Screenshot (822)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/06b29c45-1012-4a4c-a88e-ee6401a591aa)


<h3>𝟐. 𝑪𝒐𝒏𝒏𝒆𝒄𝒕 𝒕𝒉𝒆 𝒎𝒊𝒅𝒑𝒐𝒊𝒏𝒕𝒔 𝒐𝒇 𝒆𝒂𝒄𝒉 𝒔𝒊𝒅𝒆 𝒕𝒐 𝒇𝒐𝒓𝒎 𝒇𝒐𝒖𝒓 𝒔𝒆𝒑𝒂𝒓𝒂𝒕𝒆
𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆𝒔 𝒂𝒏𝒅 𝒄𝒖𝒕 𝒐𝒖𝒕 𝒕𝒉𝒆 𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆 𝒊𝒏 𝒕𝒉𝒆 𝒄𝒆𝒏𝒕𝒆𝒓.</h3>

![Screenshot (823)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/d2c83fe6-bc93-4bf3-b383-a1ce5858963d)


<h3>𝟐. 𝑪𝒐𝒏𝒏𝒆𝒄𝒕 𝒕𝒉𝒆 𝒎𝒊𝒅𝒑𝒐𝒊𝒏𝒕𝒔 𝒐𝒇 𝒆𝒂𝒄𝒉 𝒔𝒊𝒅𝒆 𝒕𝒐 𝒇𝒐𝒓𝒎 𝒇𝒐𝒖𝒓 𝒔𝒆𝒑𝒂𝒓𝒂𝒕𝒆
𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆𝒔 𝒂𝒏𝒅 𝒄𝒖𝒕 𝒐𝒖𝒕 𝒕𝒉𝒆 𝒕𝒓𝒊𝒂𝒏𝒈𝒍𝒆 𝒊𝒏 𝒕𝒉𝒆 𝒄𝒆𝒏𝒕𝒆𝒓.</h3>

![Screenshot (824)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/5b6fd287-78f6-4142-9ade-784c26f25231)


<h3>𝟒. 𝑰𝒕𝒆𝒓𝒂𝒕𝒆 𝒊𝒏𝒇𝒊𝒏𝒊𝒕𝒆𝒍𝒚.</h3>


</ul>


<h3>𝑻𝒉𝒊𝒔 𝒓𝒆𝒑𝒊𝒕𝒊𝒐𝒏 𝒐𝒇 𝒂 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒏 𝒂 𝒔𝒆𝒍𝒇 − 𝒔𝒊𝒎𝒊𝒍𝒂𝒓 𝒘𝒂𝒚
𝒊𝒔 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒐𝒏 𝒂𝒏𝒅 𝒕𝒉𝒆 𝒑𝒓𝒐𝒄𝒆𝒔𝒔 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂
𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒑𝒓𝒐𝒄𝒆𝒔𝒔.</h3>


<h3>𝑳𝒆𝒕 𝒖𝒔 𝒄𝒐𝒏𝒔𝒊𝒅𝒆𝒓 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒐𝒇 𝒑𝒐𝒔𝒊𝒕𝒊𝒗𝒆 𝒊𝒏𝒕𝒆𝒈𝒆𝒓𝒔
{𝟏, 𝟑, 𝟗, 𝟐𝟕, … .}. 𝑳𝒆𝒕 𝒂𝒓 𝒅𝒆𝒏𝒐𝒕𝒆 𝒕𝒉𝒆 𝒓𝒕𝒉 𝒕𝒆𝒓𝒎 𝒐𝒇 𝒕𝒉𝒊𝒔 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆.
𝑻𝒉𝒆𝒏 𝒘𝒆 𝒅𝒆𝒇𝒊𝒏𝒆 𝒕𝒉𝒆 𝒓𝒕𝒉 𝒕𝒆𝒓𝒎 𝒂𝒔:</h3>

<h3 align="Center">$𝒂_𝒓 = 𝟑 × 𝒂_{𝒓-𝟏}$</h3>

<h3>𝒇𝒐𝒓 𝒓 ≥ 𝟐 𝒘𝒊𝒕𝒉 𝒕𝒉𝒆 𝒊𝒏𝒊𝒕𝒊𝒂𝒍 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 $𝒂_𝟏 = 𝟏$ . 𝑯𝒆𝒓𝒆
$𝒂_{𝒓−𝟏}$ ,𝒊𝒔 𝒊𝒕𝒔 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎.</h3>
<h3>𝑻𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒆𝒅 𝒕𝒉𝒓𝒐𝒖𝒈𝒉 𝒂 𝒑𝒓𝒐𝒈𝒓𝒂𝒎.</h3>


<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/081fff32-c394-425c-9ed8-0d2571825ce8" height=600 >





  
</ul>

<h2></h2>
<h2 align="Center">𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏 -𝟏 </h2>


<ul>


<h3>𝑨 <ins>𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏</ins> 𝒊𝒔 𝒂𝒏 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒕𝒉𝒂𝒕 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚
𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆; 𝒕𝒉𝒂𝒕 𝒊𝒔 , 𝒆𝒂𝒄𝒉 𝒕𝒆𝒓𝒎 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆
𝒊𝒔 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒂𝒔 𝒂 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒑𝒓𝒆𝒄𝒆𝒆𝒅𝒊𝒏𝒈 𝒕𝒆𝒓𝒎𝒔.</h3>


<h3><ins>𝑫𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏</ins> 𝒊𝒔 𝒂𝒍𝒔𝒐 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏.
𝒊. 𝒆. 𝑫𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂𝒏𝒐𝒕𝒉𝒆𝒓 𝒏𝒂𝒎𝒆 𝒐𝒇 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏.</h3>


<h2></h2>
<h2>𝑨.𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝑫𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏:</h2>

<ul>


<h3>𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝑫𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏 𝒄𝒐𝒏𝒔𝒊𝒔𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈
𝒔𝒕𝒆𝒑𝒔:</h3>

<ul>

<h3><ins>𝟏.𝑩𝒂𝒔𝒊𝒔 𝒔𝒕𝒆𝒑:</ins>𝑻𝒉𝒊𝒔 𝒔𝒕𝒆𝒑 𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒗𝒂𝒍𝒖𝒆 𝒐𝒓 𝒂 𝒔𝒆𝒕 𝒐𝒇
𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒗𝒂𝒍𝒖𝒆𝒔.</h3>

<h3><ins>𝟐.𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒔𝒕𝒆𝒑:</ins>𝑻𝒉𝒊𝒔 𝒔𝒕𝒆𝒑 𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒕𝒉𝒆 𝒓𝒖𝒍𝒆(𝒔) 𝒕𝒐 𝒇𝒊𝒏𝒅 𝒂 𝒏𝒆𝒘 𝒆𝒍𝒆𝒎𝒆𝒏𝒕 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒆𝒙𝒊𝒔𝒕𝒊𝒏𝒈 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔.</h3>




</ul>


<h3>𝑬𝒙𝒂𝒎𝒑𝒍𝒆 :𝟏, 𝟐, 𝟑, 𝟒, 𝟓, ….</h3>


<h3><ins>𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏:</ins>
𝑳𝒆𝒕 𝒕𝒉𝒆 𝒏𝒕𝒉 𝒕𝒆𝒓𝒎 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒃𝒆 𝒅𝒆𝒏𝒐𝒕𝒆𝒅 𝒃𝒚 𝒂𝒏 .
𝑻𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒕𝒆𝒓𝒎 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒊𝒔 𝟏 , 𝒂𝒏𝒅 𝒆𝒂𝒄𝒉 𝒔𝒖𝒄𝒄𝒆𝒔𝒔𝒊𝒗𝒆
𝒕𝒆𝒓𝒎 𝒄𝒂𝒏 𝒃𝒆 𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅 𝒃𝒚 𝒂𝒅𝒅𝒊𝒏𝒈 𝟏 𝒕𝒐 𝒕𝒉𝒆 𝒑𝒓𝒆𝒄𝒆𝒆𝒅𝒊𝒏𝒈 𝒕𝒆𝒓𝒎.
𝑻𝒉𝒖𝒔, 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒂𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3>$𝒂_𝟏 = 𝟏$</h3>
<h3>$𝒂_𝒏 = 𝒂_{𝒏−𝟏} + 𝟏 , 𝒏 ≥ 𝟐$</h3>

<h3>𝑾𝒆 𝒄𝒂𝒏 𝒘𝒓𝒊𝒕𝒆 𝒂 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒑𝒓𝒐𝒈𝒓𝒂𝒎 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/bd7d8119-619c-43c8-8927-d144b89e863d" height=600 >




</ul>

<h2></h2>
<h2>𝑩.𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚 𝑫𝒆𝒇𝒊𝒏𝒆𝒅 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔</h2>

<ul>

<h3>𝑨 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒘𝒉𝒐𝒔𝒆 𝒅𝒐𝒎𝒂𝒊𝒏 𝒊𝒔 𝒕𝒉𝒆 𝒔𝒆𝒕 𝒐𝒇 𝒏𝒐𝒏 − 𝒏𝒆𝒈𝒂𝒕𝒊𝒗𝒆
𝒊𝒏𝒕𝒆𝒈𝒆𝒓𝒔 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆
𝒅𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏. 𝑻𝒉𝒆 𝒃𝒂𝒔𝒊𝒔 𝒔𝒕𝒆𝒑 𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒕𝒉𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒔𝒐𝒎𝒆
𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒗𝒂𝒍𝒖𝒆𝒔 𝒂𝒏𝒅 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒔𝒕𝒆𝒑 𝒑𝒓𝒐𝒗𝒊𝒅𝒆𝒔 𝒂 𝒘𝒂𝒚
𝒕𝒐 𝒄𝒂𝒍𝒄𝒖𝒍𝒂𝒕𝒆 𝒕𝒉𝒆 𝒗𝒂𝒍𝒖𝒆 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒐𝒕𝒉𝒆𝒓
𝒊𝒏𝒕𝒆𝒈𝒆𝒓𝒔.</h3>


<h3><ins>𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏:</ins></h3>

<h3>𝑾𝒓𝒊𝒕𝒆 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒅𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒇(𝒙) = $𝟐^𝒙$
𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒔𝒆𝒕 𝒐𝒇 𝒏𝒂𝒕𝒖𝒓𝒂𝒍 𝒏𝒖𝒎𝒃𝒆𝒓𝒔(𝒊𝒏𝒄𝒍𝒖𝒅𝒊𝒏𝒈 𝟎)
𝒕𝒐 𝒕𝒉𝒆 𝒔𝒆𝒕 𝒐𝒇 𝒏𝒂𝒕𝒖𝒓𝒂𝒍 𝒏𝒖𝒎𝒃𝒆𝒓𝒔.</h3>


<h3><ins>𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏:</ins></h3>

<h3>𝑺𝒊𝒏𝒄𝒆 𝒇(𝟎) = 𝟏 𝒂𝒏𝒅 𝒇(𝒙 + 𝟏) = $𝟐^{𝒙+𝟏}$ = 𝟐 × $𝟐^𝒙$ = 𝟐 × 𝒇(𝒙),
𝒕𝒉𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3>𝒊. 𝒆. 𝒇(𝟎) = 𝟏(𝑩𝒂𝒔𝒆 𝑪𝒂𝒔𝒆)</h3>
<h3>𝒇(𝟏) = $𝟐^𝟏$ 𝒐𝒓 𝟐 × 𝒇(𝟎) = 𝟐 × 𝟏 = 𝟐</h3>
<h3>𝒇(𝟐) = $𝟐^𝟐$ 𝒐𝒓 𝟐 × 𝒇(𝟏) = 𝟐 × 𝟐 = 𝟒</h3>
<h3>𝒇(𝟑) = $𝟐^𝟑$ 𝒐𝒓 𝟐 × 𝒇(𝟐) = 𝟐 × 𝟒 = 𝟖</h3>
<h3>… ….</h3>

<h3>𝑯𝒆𝒏𝒄𝒆:</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/d6f1d8e8-c464-4468-86ae-58bb3bf2f722" height=100 >

<h3>𝑻𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆 𝒕𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒆𝒅 𝒃𝒚
𝒂 𝒑𝒓𝒐𝒈𝒓𝒂𝒎:</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/23810140-a33e-4cd9-8d4a-6d81bf8be83a" height=550 width=700>


<h3><ins>𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐:</ins></h3>

<h3>𝑾𝒓𝒊𝒕𝒆 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒅𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒇(𝒙) = 𝒙!,
𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒔𝒆𝒕 𝒐𝒇 𝒏𝒂𝒕𝒖𝒓𝒂𝒍 𝒏𝒖𝒎𝒃𝒆𝒓𝒔(𝒊𝒏𝒄𝒍𝒖𝒅𝒊𝒏𝒈 𝟎)𝒕𝒐 𝒕𝒉𝒆 𝒔𝒆𝒕
𝒐𝒇 𝒏𝒂𝒕𝒖𝒓𝒂𝒍 𝒏𝒖𝒎𝒃𝒆𝒓𝒔.</h3>


<h3>𝑰𝒇 𝒘𝒆 𝒔𝒆𝒆 𝒇𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒖𝒔𝒊𝒏𝒈 𝒊𝒕𝒆𝒓𝒂𝒕𝒊𝒐𝒏 ∶</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟎 = 𝟏</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟏 = 𝟏</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟐 = 𝟏 ∗ 𝟐 = 𝟐</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟑 = 𝟏 ∗ 𝟐 ∗ 𝟑 = 𝟔</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟒 = 𝟏 ∗ 𝟐 ∗ 𝟑 ∗ 𝟒 = 𝟐𝟒</h3>
<h3>𝑭𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒐𝒇 𝟓 = 𝟏 ∗ 𝟐 ∗ 𝟑 ∗ 𝟒 ∗ 𝟓 = 𝟏𝟐𝟎</h3>
<h3>… ….</h3>

<h3>𝑻𝒉𝒆 𝒔𝒂𝒎𝒆 𝒕𝒉𝒊𝒏𝒈 𝒄𝒂𝒏 𝒃𝒆 𝒂𝒄𝒉𝒊𝒆𝒗𝒆𝒅 𝒃𝒚 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒐𝒏:</h3>
<h3>𝒇(𝟎) = 𝟏</h3>
<h3>𝒇(𝟏) = 𝟏 × 𝒇(𝟎) (𝒊. 𝒆. 𝟏 × 𝟎!) = 𝟏</h3>
<h3>𝒇(𝟐) = 𝟐 × 𝒇(𝟏) (𝒊. 𝒆. 𝟐 × 𝟏!) = 𝟐</h3>
<h3>𝒇(𝟑) = 𝟑 × 𝒇(𝟐) (𝒊. 𝒆. 𝟑 × 𝟐!) = 𝟔</h3>
<h3>𝒇(𝟒) = 𝟒 × 𝒇(𝟑) (𝒊. 𝒆. 𝟒 × 𝟑!) = 𝟐𝟒</h3>
<h3>𝒇(𝟓) = 𝟓 × 𝒇(𝟒) (𝒊. 𝒆. 𝟓 × 𝟒!) = 𝟏𝟐𝟎</h3>
<h3>… … … ..</h3>


<h3>𝑯𝒆𝒏𝒄𝒆 𝒕𝒉𝒆 𝒇𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚:</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/2d419b82-61fc-451f-b3fd-522d20176e50" height=100 >


<h3>𝑾𝒆 𝒄𝒂𝒏 𝒘𝒓𝒊𝒕𝒆 𝒆𝒙𝒉𝒊𝒃𝒊𝒕 𝒊𝒕 𝒕𝒉𝒓𝒐𝒖𝒈𝒉 𝒂 𝒑𝒓𝒐𝒈𝒓𝒂𝒎:</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/561d8fd5-904a-43ee-aabc-c377e13bf551" height=550 width=700>





</ul>


<h2></h2>
<h2>𝑪.𝑹𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚 𝑫𝒆𝒇𝒊𝒏𝒆𝒅 𝑺𝒆𝒕𝒔</h2>

<ul>

<h3>𝑨 𝒔𝒆𝒕 𝒊𝒔 𝒔𝒂𝒊𝒅 𝒕𝒐 𝒃𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒊𝒇 𝒕𝒉𝒆 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔 𝒐𝒇
𝒕𝒉𝒆 𝒔𝒆𝒕 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒅𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏.
𝑻𝒉𝒆 𝒃𝒂𝒔𝒊𝒔 𝒔𝒕𝒆𝒑 𝒅𝒆𝒇𝒊𝒏𝒆𝒔 𝒕𝒉𝒆 𝒑𝒓𝒊𝒎𝒊𝒕𝒊𝒗𝒆 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒕
𝒂𝒏𝒅 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒅𝒆𝒇𝒊𝒏𝒊𝒕𝒊𝒐𝒏 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒆𝒔 𝒕𝒉𝒆 𝒐𝒕𝒉𝒆𝒓 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔
𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒕.</h3>


<h3>𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏: 𝑨 = {𝟏, 𝟒, 𝟕, 𝟏𝟎, … . .}</h3>


<h3><ins>𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏:</ins></h3>

<h3>𝑻𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒕𝒆𝒓𝒎 𝒊𝒔 𝟏, 𝒂𝒏𝒅 𝒆𝒂𝒄𝒉 𝒔𝒖𝒄𝒄𝒆𝒔𝒔𝒊𝒗𝒆 𝒕𝒆𝒓𝒎 𝒄𝒂𝒏 𝒃𝒆
𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎 𝒃𝒚 𝒂𝒅𝒅𝒊𝒏𝒈 𝟑. 𝑻𝒉𝒖𝒔
𝒕𝒉𝒆 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒕 𝑨 𝒄𝒂𝒏 𝒃𝒆 𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆𝒍𝒚
𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>
<h3>(𝒊) 𝟏 ∈ 𝑨</h3>
<h3>(𝒊𝒊)𝒊𝒇 𝒙 ∈ 𝑨 , 𝒕𝒉𝒆𝒏 𝒙 + 𝟑 ∈ 𝑨</h3>
<h3>𝑾𝒆 𝒄𝒂𝒏 𝒄𝒓𝒆𝒂𝒕𝒆 𝒂 𝒑𝒓𝒐𝒈𝒓𝒂𝒎 𝒕𝒐 𝒄𝒉𝒆𝒄𝒌 𝒘𝒉𝒆𝒕𝒉𝒆𝒓 𝒕𝒉𝒆 𝒆𝒍𝒆𝒎𝒆𝒏𝒕 𝒊𝒔
𝒊𝒏 𝒔𝒆𝒕 𝒐𝒓 𝒏𝒐𝒕.</h3>

![Screenshot (833)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/511e9520-bb63-4cde-8a49-b11a04ca40b7)


<h3>𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐: 𝑨 = {𝟐, 𝟓, 𝟏𝟏, 𝟐𝟑, … . .}</h3>

<h3><ins>𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏:</ins></h3>


<h3>𝑻𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒕𝒆𝒓𝒎 𝒊𝒔 𝟐, 𝒂𝒏𝒅 𝒆𝒂𝒄𝒉 𝒔𝒖𝒄𝒄𝒆𝒔𝒔𝒊𝒗𝒆 𝒕𝒆𝒓𝒎 𝒄𝒂𝒏 𝒃𝒆
𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎 𝒃𝒚 𝒎𝒖𝒍𝒕𝒊𝒑𝒍𝒚𝒊𝒏𝒈 𝒊𝒕 𝒃𝒚 𝟐
𝒂𝒏𝒅 𝒂𝒅𝒅𝒊𝒏𝒈 𝟏. 𝑻𝒉𝒖𝒔 𝒕𝒉𝒆 𝒆𝒍𝒆𝒎𝒆𝒏𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒆𝒕 𝑨 𝒄𝒂𝒏 𝒃𝒆
𝒅𝒆𝒇𝒊𝒏𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒊𝒔𝒗𝒆𝒍𝒚 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>
<h3>(𝒊) 𝟐 ∈ 𝑨</h3>
<h3>(𝒊𝒊)𝒊𝒇 𝒙 ∈ 𝑨 , 𝒕𝒉𝒆𝒏 𝒙 + 𝟑 ∈ 𝑨</h3>
<h3>𝑾𝒆 𝒄𝒂𝒏 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒆 𝒂 𝒔𝒊𝒎𝒊𝒍𝒂𝒓 𝒑𝒓𝒐𝒈𝒓𝒂𝒎 𝒂𝒔 𝒂𝒃𝒐𝒗𝒆 𝒂𝒏𝒅 𝒄𝒉𝒆𝒄𝒌
𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆.</h3>









</ul>



</ul>



<h2></h2>
<h2 align="Center">𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏 -𝟐 </h2>

<ul>

<h3>𝑻𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒄𝒂𝒏 𝒂𝒍𝒔𝒐 𝒃𝒆 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒆𝒅 𝒃𝒚 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒂𝒏𝒅
𝒕𝒆𝒓𝒎𝒔 𝒂𝒔 𝒘𝒆 𝒔𝒆𝒆 ∶ 𝟎, 𝟐, 𝟒, 𝟔, 𝟖 … .𝒊𝒔 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒐𝒇 𝒆𝒗𝒆𝒏
𝒏𝒖𝒎𝒃𝒆𝒓𝒔.</h3>


<h3>𝒊𝒇 𝒘𝒆 𝒈𝒐 𝒕𝒉𝒓𝒐𝒖𝒈𝒉 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒍𝒊𝒌𝒆 $𝒕_𝟎$, $𝒕_𝟏$ , $𝒕_𝟐$ , $𝒕_𝟑$ , … , $𝒕_𝒏$ .</h3>
<h3>𝑾𝒉𝒆𝒓𝒆,</h3>

<h3>$𝒕_𝟎$ = 𝟎</h3>
<h3>$𝒕_𝟏$ = $𝒕_𝟎$ + 𝟐 = 𝟐</h3>
<h3>$𝒕_𝟐$ = $𝒕_𝟏$ + 𝟐 = 𝟒</h3>
<h3>… ….</h3>
<h3>$𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟐</h3>

<h3>𝒊𝒇 𝑻(𝒏) 𝒅𝒆𝒏𝒐𝒕𝒆𝒔 𝒕𝒉𝒆 𝒕𝒊𝒎𝒆 𝒄𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝒐𝒇 𝒕𝒉𝒆 𝒂𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎 .</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/d69f6890-f6a1-4dd8-82a3-294254a0c52c" height=200 >


<h3>𝑻𝒉𝒆𝒓𝒆 𝒂𝒓𝒆 𝒕𝒘𝒐 𝒕𝒚𝒑𝒆𝒔 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏:</h3>

<ul>
  
<h3>→ 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔.</h3>
<h3>→ 𝑵𝒐𝒏 − 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔.</h3>

</ul>

<br>

<br>


![Screenshot (835)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/d52d54b6-0475-447a-856f-5fb5957a6ddf)


<h2></h2>
<h2 align="Center">𝑨.𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔</h2>


<ul>

<h3>𝑳𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆{ $𝒕_𝟎$ , $𝒕_𝟏$, … . , $𝒕_𝒏$ }
𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒔 𝒕𝒉𝒆 𝒇𝒊𝒏𝒂𝒍 𝒕𝒆𝒓𝒎 𝒕𝒏 𝒂𝒔 𝒂 𝒍𝒊𝒏𝒆𝒂𝒓 𝒄𝒐𝒎𝒃𝒊𝒏𝒂𝒕𝒊𝒐𝒏 𝒐𝒇
𝒊𝒕𝒔 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎𝒔 𝒊𝒏 𝒂 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝒇𝒐𝒓𝒎.</h3>

<h3>𝑳𝒊𝒏𝒆𝒂𝒓 𝒓𝒖𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒍𝒐𝒐𝒌𝒔 𝒍𝒊𝒌𝒆 ∶</h3>

<h3>$𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + $𝒂_𝟐$ $𝒕_{𝒏−𝟐}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝒇(𝒏)</h3>


<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/c63dd844-a0cf-469b-b001-1dc65953de9f" height=100 >




<h3>𝒘𝒉𝒆𝒓𝒆, 𝒌 𝒂𝒏𝒅 $𝒂_𝒊$ 𝒕𝒆𝒓𝒎𝒔 𝒂𝒓𝒆 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒂𝒏𝒅 $𝒂_𝟎$ , $𝒂_𝒌$ 𝒂𝒓𝒆
𝒏𝒐𝒏 − 𝒛𝒆𝒓𝒐 𝒂𝒏𝒅 𝒌 𝒃𝒆𝒊𝒏𝒈 𝒕𝒉𝒆 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>








</ul>


<h2></h2>
<h2 align="Center">𝑨.𝟏.𝑫𝒊𝒗𝒊𝒔𝒊𝒐𝒏 𝒐𝒇 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 </h2>

<ul>



![Screenshot (837)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/b1ef353a-edcc-46ce-a36a-1710b0c2dbfe)




</ul>


<h2></h2>
<h2 align="Center">𝑨.𝟏.𝒂.𝑩𝒂𝒔𝒆𝒅 𝑶𝒏 𝑶𝒓𝒅𝒆𝒓</h2>

<ul>

<h3>𝑻𝒉𝒆 𝒏𝒖𝒎𝒃𝒆𝒓 𝒐𝒇 𝒑𝒓𝒆𝒄𝒆𝒅𝒊𝒏𝒈 𝒕𝒆𝒓𝒎𝒔 𝒖𝒔𝒆𝒅 𝒇𝒐𝒓 𝒄𝒐𝒎𝒑𝒖𝒕𝒊𝒏𝒈
𝒕𝒉𝒆 𝒑𝒓𝒆𝒔𝒆𝒏𝒕 𝒕𝒆𝒓𝒎 𝒐𝒇 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅
𝒕𝒉𝒆 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>

<br>
<br>

<h3><ins>𝟏. 𝑭𝒊𝒓𝒔𝒕 𝑶𝒓𝒅𝒆𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</ins></h3>


<h3>𝑻𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒍 𝒇𝒐𝒓𝒎 𝒐𝒇 𝒂 𝒇𝒊𝒓𝒔𝒕 − 𝒐𝒓𝒅𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>
<h3 align="Center"> $𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ = 𝒇(𝒏)</h3>
<h3>𝑰𝒇 $𝒕_𝒏 𝒊𝒔 𝒄𝒐𝒎𝒑𝒖𝒕𝒆𝒅 𝒖𝒔𝒊𝒏𝒈 𝒐𝒏𝒍𝒚 𝒐𝒏𝒆 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎, 𝒕𝒉𝒆𝒏 𝒕𝒉𝒆
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂 𝒇𝒊𝒓𝒔𝒕 − 𝒐𝒓𝒅𝒆𝒓 𝒍𝒊𝒏𝒆𝒂𝒓
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝑯𝒐𝒘 𝒇𝒊𝒏𝒅 𝒘𝒉𝒆𝒕𝒉𝒆𝒓 𝒂𝒏 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒇𝒊𝒓𝒔𝒕 𝒐𝒓𝒅𝒆𝒓 𝒐𝒓 𝒏𝒐𝒕?</h3>
<h3>𝑳𝒆𝒕𝒔 𝒕𝒂𝒌𝒆 𝒂𝒏 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏: $𝒕_𝒏$ − $𝒕_{𝒏−𝟏}$ − 𝟕 $𝒕_{𝒏−𝟐}$ = 𝟎. </h3>


<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/10bab043-4bb7-4010-80e0-8f144f18b857" height=150 >


<h3>𝑯𝒆𝒏𝒄𝒆 𝒐𝒓𝒅𝒆𝒓 𝒘𝒊𝒍𝒍 𝒃𝒆 = 𝒏 − (𝒏 − 𝟐) = 𝟐 𝒊. 𝒆.,
𝑫𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝒃𝒆𝒕𝒘𝒆𝒆𝒏 𝒕𝒉𝒆 𝒉𝒊𝒈𝒉𝒆𝒔𝒕 𝒂𝒏𝒅 𝒍𝒐𝒘𝒆𝒔𝒕 𝒔𝒖𝒃𝒔𝒄𝒓𝒊𝒑𝒕𝒔
𝒐𝒇 𝒕𝒉𝒆 𝒅𝒆𝒑𝒆𝒏𝒅𝒆𝒏𝒕 𝒗𝒂𝒓𝒊𝒂𝒃𝒍𝒆 𝒊𝒏 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>


<h3>𝒊𝒇 𝒘𝒆 𝒔𝒆𝒆 𝒕𝒉𝒆 𝒇𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍,</h3>
<h3> $𝒕_𝟎$ = 𝟏</h3>
<h3> $𝒕_𝟏$ = $𝒕_𝟎$ × 𝟏 = 𝟏</h3>
<h3> $𝒕_𝟐$ = $𝒕_𝟏$ × 𝟐 = 𝟐</h3>
<h3>… ..</h3>
<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ × 𝒏 </h3>
<h3>𝑩𝒚 𝒂𝒃𝒐𝒗𝒆 𝒘𝒆 𝒕𝒂𝒌𝒆 𝒕𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒕𝒐 𝒄𝒐𝒎𝒑𝒖𝒕𝒆, 𝒘𝒆 𝒈𝒆𝒕:</h3>
<h3>$𝒕_𝒏$ − 𝒏 $𝒕_{𝒏−𝟏}$ = 𝟎</h3>
<h3>𝑯𝒆𝒏𝒄𝒆, 𝒏 − (𝒏 − 𝟏) = 𝟏 𝒊. 𝒆. 𝒇𝒊𝒓𝒔𝒕 𝒐𝒓𝒅𝒆𝒓.</h3>

<h3>𝑨𝒍𝒔𝒐 𝒊𝒇 𝒘𝒆 𝒕𝒂𝒌𝒆 𝒕𝒉𝒆 𝒕𝒊𝒎𝒆 𝒄𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝑻(𝒏), 𝒉𝒆𝒏𝒄𝒆 𝒑𝒆𝒓
𝑻(𝒏 − 𝟏) 𝒊𝒕 𝒕𝒂𝒌𝒆𝒔 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒕𝒊𝒎𝒆 𝒄 𝒊. 𝒆. 𝑻(𝟏) 𝒊𝒏 𝒔𝒕𝒂𝒄𝒌.</h3>

<h3>𝑻𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆, 𝑻(𝒏) = 𝑻(𝒏 − 𝟏) + 𝑻(𝟏) 𝒐𝒓
𝑻(𝒏) = 𝑻(𝒏 − 𝟏) + 𝑪 , 𝒘𝒉𝒆𝒓𝒆 𝑪 𝒊𝒔 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕.</h3>

<h3>𝑨𝒏𝒅 𝑪 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒔 𝟏 𝒖𝒏𝒊𝒕 𝒐𝒇 𝒕𝒊𝒎𝒆 𝒂𝒏𝒅 𝑻(𝟏) = 𝟏 ,
𝒉𝒆𝒏𝒄𝒆 𝑪 = 𝑻(𝟏).</h3>


<h3>𝑨𝒏𝒅 𝒊𝒕 𝒊𝒔 𝒏𝒐𝒕 𝒏 × 𝑻(𝒏 − 𝟏) 𝒂𝒔 𝒕𝒉𝒆 𝒎𝒖𝒍𝒕𝒊𝒑𝒍𝒊𝒄𝒂𝒕𝒊𝒐𝒏 𝒕𝒂𝒌𝒆𝒔 𝒊𝒏
𝒔𝒕𝒂𝒄𝒌 𝒇𝒐𝒓 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒕𝒊𝒎𝒆 , 𝒉𝒆𝒏𝒄𝒆 𝒐𝒏𝒍𝒚 𝒊𝒕 𝒎𝒂𝒕𝒕𝒆𝒓𝒔 𝒊𝒔
𝑻(𝒏 − 𝟏) ,𝒊. 𝒆. 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒖𝒔𝒆 𝒐𝒇 𝒔𝒕𝒂𝒄𝒌
′𝒔 𝒑𝒖𝒔𝒉 𝒂𝒏𝒅 𝒑𝒐𝒑.</h3>

<h3>𝑯𝒆𝒏𝒄𝒆 𝒊𝒕 𝒈𝒐𝒆𝒔 𝒍𝒊𝒌𝒆:</h3>

<h3>𝑻(𝒏) =</h3>
<h3>⟹ 𝑻(𝒏 − 𝟏) + 𝑻(𝟏)</h3>
<h3>⟹ 𝑻(𝒏 − 𝟐) + 𝑻(𝟏) + 𝑻(𝟏)</h3>
<h3>⟹ 𝑻(𝒏 − 𝟑) + 𝑻(𝟏) + 𝑻(𝟏) + 𝑻(𝟏)</h3>

<h3>𝑾𝒆 𝒄𝒂𝒏 𝒇𝒖𝒓𝒕𝒉𝒆𝒓 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕 𝒕𝒉𝒆 𝒂𝒃𝒐𝒗𝒆 𝒂𝒔 ∶ −
$𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟏 (𝑭𝒐𝒓 𝒔𝒊𝒏𝒈𝒍𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 `𝒕`)</h3>
<h3>𝒐𝒓, $𝒕_𝒏$ − $𝒕_{𝒏−𝟏}$ = 𝟏.</h3>

<h3>𝑯𝒆𝒏𝒄𝒆 𝒉𝒆𝒓𝒆 𝒂𝒍𝒔𝒐 𝒘𝒆 𝒈𝒆𝒕 ∶ 𝒏 − (𝒏 − 𝟏) = 𝟏,𝒊. 𝒆. 𝒇𝒊𝒓𝒔𝒕 − 𝒐𝒓𝒅𝒆𝒓
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>


<br>
<br>

<h3><ins>𝟐. 𝑺𝒆𝒄𝒐𝒏𝒅 𝑶𝒓𝒅𝒆𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</ins></h3>

<h3>𝑻𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒊𝒄 𝒇𝒐𝒓𝒎 𝒐𝒇 𝒂 𝒔𝒆𝒄𝒐𝒏𝒅 − 𝒐𝒓𝒅𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒈𝒊𝒗𝒆𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3>$𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + $𝒂_𝟐$ $𝒕_{𝒏−𝟐}$ = 𝒇(𝒏)</h3>


<h3>𝑭𝒊𝒃𝒐𝒏𝒂𝒄𝒄𝒊 𝒔𝒆𝒓𝒊𝒆𝒔 𝒘𝒉𝒊𝒄𝒉 𝒊𝒔 𝒊𝒏𝒗𝒆𝒏𝒕𝒆𝒅 𝒃𝒚 𝑳𝒆𝒐𝒏𝒂𝒓𝒅𝒐 𝑭𝒊𝒃𝒐𝒏𝒂𝒄𝒄𝒊,
𝒂𝒍𝒔𝒐 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝑳𝒆𝒐𝒏𝒂𝒓𝒅𝒐 𝑩𝒐𝒏𝒂𝒄𝒄𝒊 𝒂𝒏 𝒊𝒕𝒂𝒍𝒊𝒂𝒏 𝒎𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒊𝒂𝒏.
𝑻𝒉𝒆 𝒔𝒆𝒓𝒊𝒆𝒔 𝒔𝒕𝒂𝒕𝒆𝒔:</h3>


<h3>𝑻𝒉𝒆 𝒃𝒂𝒔𝒆 𝒐𝒓 𝒔𝒕𝒂𝒓𝒕𝒊𝒏𝒈 𝒏𝒖𝒎𝒃𝒆𝒓𝒔 𝒂𝒓𝒆 𝟎 𝒂𝒏𝒅 𝟏. 𝑻𝒉𝒂𝒕 𝒊𝒔:</h3>
<h3>𝒇𝒊𝒃(𝟎) = 𝟎</h3>
<h3>𝒇𝒊𝒃(𝟏) = 𝟏</h3>
<h3>𝒇𝒊𝒃(𝟐) = 𝒇𝒊𝒃(𝟎) + 𝒇𝒊𝒃(𝟏) = 𝟎 + 𝟏 = 𝟏</h3>
<h3>𝒇𝒊𝒃(𝟑) = 𝒇𝒊𝒃(𝟐) + 𝒇𝒊𝒃(𝟏) = 𝟏 + 𝟏 = 𝟐</h3>
<h3>𝒇𝒊𝒃(𝟒) = 𝒇𝒊𝒃(𝟑) + 𝒇𝒊𝒃(𝟐) = 𝟐 + 𝟏 = 𝟑</h3>
<h3>… …</h3>
<h3>𝑾𝒆 𝒄𝒂𝒏 𝒓𝒆𝒍𝒂𝒕𝒆 𝒕𝒉𝒊𝒔 𝒘𝒊𝒕𝒉 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>


<h3>𝒇𝒊𝒃(𝒏) = 𝒇𝒊𝒃(𝒏 − 𝟏) + 𝒇𝒊𝒃(𝒏 − 𝟐).</h3>
<h3>𝒐𝒓, 𝑻(𝒏) = 𝑻(𝒏 − 𝟏) + 𝑻(𝒏 − 𝟐).</h3>
<h3>𝑯𝒆𝒏𝒄𝒆 𝒇𝒐𝒓 𝒔𝒊𝒏𝒈𝒍𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 `𝒕` ∶</h3>
<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + $𝒕_{𝒏−𝟐}$ .</h3>


<h3>𝑨𝒏𝒅 𝒇𝒊𝒃𝒐𝒏𝒂𝒄𝒄𝒊 𝒔𝒆𝒓𝒊𝒆𝒔 𝒊𝒔 `𝒔𝒆𝒄𝒐𝒏𝒅 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆`.</h3>
<h3> 𝒊. 𝒆. $𝒕_𝒏$ − $𝒕_{𝒏−𝟏}$ − $𝒕_{𝒏−𝟐}$ = 𝟎 </h3>
<h3> ⟹ 𝒏 − (𝒏 − 𝟐) = 𝟐, 𝒉𝒆𝒏𝒄𝒆 𝒔𝒆𝒄𝒐𝒏𝒅 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆.</h3>


<br>
<br>

<h3><ins>𝟑. 𝑯𝒊𝒈𝒉𝒆𝒓 𝑶𝒓𝒅𝒆𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</ins></h3>

<h3>𝑯𝒊𝒈𝒉𝒆𝒓 − 𝒐𝒓𝒅𝒆𝒓 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒐𝒓𝒅𝒆𝒓 𝒌
𝒄𝒂𝒏 𝒃𝒆 𝒇𝒐𝒓𝒎𝒖𝒍𝒂𝒕𝒆𝒅 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3> $𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝒇(𝒏)</h3>
<h3>𝒊. 𝒆.,</h3>

<img src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/c63dd844-a0cf-469b-b001-1dc65953de9f" height=100 >


<h3>𝑯𝒆𝒓𝒆 $𝒂_𝒊$ 𝒂𝒏𝒅 𝒌 𝒂𝒓𝒆 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒔.</h3>


</ul>


<h2></h2>
<h2 align="Center">𝑨.𝟏.𝒃. 𝑩𝒂𝒔𝒆𝒅 𝒐𝒏 𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒊𝒕𝒚</h2>

<ul>

<h3><ins>𝑨. 𝑯𝒐𝒎𝒐𝒈𝒆𝒐𝒖𝒔 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</ins></h3>

<h3>𝑺𝒖𝒑𝒑𝒐𝒔𝒆 𝒘𝒆 𝒉𝒂𝒗𝒆 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>
<h3> $𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝒇(𝒏) 𝒂𝒏𝒅 𝒊𝒇 𝒇(𝒏) = 𝟎,
𝒊𝒕 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3><ins>𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒊𝒕𝒚 𝒕𝒆𝒔𝒕</ins>: 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒆 𝒕𝒏 𝒂𝒏𝒅 𝒂𝒍𝒍 𝒊𝒕𝒔 𝒇𝒂𝒄𝒕𝒐𝒓𝒔 $𝒕_{𝒏−𝟏}$,
$𝒕_{𝒏−𝟐}$, … . . , $𝒕_{𝒏−𝒌}$ 𝒘𝒊𝒕𝒉 𝒛𝒆𝒓𝒐.</h3>
<h3>𝑬𝒈: 𝑭𝒊𝒃𝒐𝒏𝒂𝒄𝒄𝒊 𝑺𝒆𝒓𝒊𝒆𝒔 ∶</h3>
<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + $𝒕_{𝒏−𝟐}$ </h3>
<h3>𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒏𝒈 $𝒕_𝒏$, $𝒕_{𝒏−𝟏}$, $𝒕_{𝒏−𝟐}$ 𝒘𝒊𝒕𝒉 𝒛𝒆𝒓𝒐 𝒘𝒆 𝒈𝒆𝒕:𝟎 = 𝟎 + 𝟎</h3>
<h3>𝑻𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆 , $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + $𝒕_{𝒏−𝟐}$ 𝒊𝒔 𝒂 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>

<br>
<br>

<h3><ins>𝑩. 𝑵𝒐𝒏 − 𝑯𝒐𝒎𝒐𝒈𝒆𝒐𝒖𝒔 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</ins></h3>
<h3>𝑺𝒖𝒑𝒑𝒐𝒔𝒆 𝒘𝒆 𝒉𝒂𝒗𝒆 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>
<h3>$𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝒇(𝒏) 𝒂𝒏𝒅 𝒊𝒇 𝒇(𝒏) ≠ 𝟎,
𝒊𝒕 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂 𝒏𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝑳𝒆𝒕𝒔 𝒕𝒂𝒌𝒆 𝒇𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 ∶</h3>
<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟏</h3>
<h3>𝑨𝒑𝒑𝒍𝒚𝒊𝒏𝒈 𝒕𝒉𝒆 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒊𝒕𝒚 𝒕𝒆𝒔𝒕:</h3>
<h3>𝟎 = 𝟎 + 𝟏</h3>
<h3>= 𝟏</h3>
<h3>𝑯𝒆𝒏𝒄𝒆, 𝒇𝒐𝒓 𝒇𝒂𝒄𝒕𝒐𝒓𝒊𝒂𝒍 𝒊𝒕 𝒊𝒔 𝒏𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒊𝒏 𝒏𝒂𝒕𝒖𝒓𝒆.</h3>


</ul>


<h2></h2>
<h2 align="Center">𝑨.𝟏.𝒄. 𝑩𝒂𝒔𝒆𝒅 𝒐𝒏 𝑪𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕</h2>

<ul>

<h3>𝑰𝒏 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒊𝒄 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 ∶
$𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝒇(𝒏), 𝒕𝒉𝒆 𝒕𝒆𝒓𝒎𝒔 $𝒂_𝒊$ 𝒄𝒂𝒏 𝒃𝒆
𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒔 𝒐𝒓 𝒗𝒂𝒓𝒊𝒂𝒃𝒍𝒆𝒔 .</h3>
<h3>𝑩𝒂𝒔𝒆𝒅 𝒐𝒏 𝒕𝒉𝒊𝒔 𝒔𝒄𝒆𝒏𝒂𝒓𝒊𝒐 , 𝒘𝒆 𝒄𝒂𝒏 𝒄𝒍𝒂𝒔𝒔𝒊𝒇𝒚 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒊𝒏𝒕𝒐 𝒕𝒘𝒐 𝒕𝒚𝒑𝒆𝒔:</h3>

<ul>
  
<h3>𝟏)𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒘𝒊𝒕𝒉 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒔 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒔.</h3>
<h3>𝟐)𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒘𝒊𝒕𝒉 𝒗𝒂𝒓𝒊𝒂𝒃𝒍𝒆 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒔.</h3>

</ul>

<h3>𝑬𝒙𝒂𝒎𝒑𝒍𝒆: $𝒕_𝒏$ = 𝒏 × $𝒕_{𝒏−𝟐}$ </h3>

<h3>𝑻𝒉𝒊𝒔 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒅𝒆𝒑𝒆𝒏𝒅𝒆𝒏𝒕 𝒐𝒏 𝒕𝒉𝒆 𝒗𝒂𝒓𝒊𝒂𝒃𝒍𝒆
`𝒏` 𝒂𝒏𝒅 𝒅𝒐𝒆𝒔𝒏𝒐𝒕 𝒉𝒂𝒗𝒆 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒔. 𝑯𝒐𝒘𝒆𝒗𝒆𝒓,
𝒊𝒏 𝒂𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎 𝒔𝒕𝒖𝒅𝒚 , 𝒕𝒉𝒆𝒔𝒆 𝒌𝒊𝒏𝒅𝒔 𝒐𝒇 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒂𝒓𝒆 𝒓𝒂𝒓𝒆 𝒂𝒏𝒅
𝒎𝒐𝒔𝒕𝒍𝒚 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔
𝒂𝒓𝒆 𝒆𝒏𝒄𝒐𝒖𝒏𝒕𝒆𝒓𝒆𝒅.</h3>


</ul>

</ul>


<h2></h2>
<h2 align="Center">𝑩.𝑵𝒐𝒏 − 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔</h2>

<ul>


<h3>𝑻𝒉𝒆 𝒏𝒐𝒏 − 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒐𝒇 𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆
 { $𝒕_𝟎$, $𝒕_𝟏$ , … . , $𝒕_𝒏$ } 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒔 𝒕𝒏 𝒂𝒔 𝒂 𝒏𝒐𝒏 − 𝒍𝒊𝒏𝒆𝒂𝒓 𝒄𝒐𝒎𝒃𝒊𝒏𝒂𝒕𝒊𝒐𝒏
𝒐𝒇 𝒊𝒕𝒔 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎𝒔. 𝑰𝒏 𝒂𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎 𝒔𝒕𝒖𝒅𝒚, 𝒂 𝒖𝒏𝒊𝒒𝒖𝒆 𝒇𝒐𝒓𝒎 𝒐𝒇 
𝒏𝒐𝒏 − 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 , 𝒄𝒂𝒍𝒍𝒆𝒅 
𝒅𝒊𝒗𝒊𝒅𝒆 − 𝒂𝒏𝒅 − 𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 𝒊𝒔 𝒐𝒇𝒕𝒆𝒏 
𝒆𝒏𝒄𝒐𝒖𝒏𝒕𝒆𝒓𝒆𝒅. </h3>
 
<h3>𝑻𝒉𝒆 𝒅𝒊𝒗𝒊𝒅𝒆 − 𝒂𝒏𝒅 − 𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 𝒂𝒓𝒆 𝒐𝒇 𝒕𝒉𝒆 
𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒇𝒐𝒓𝒎: </h3>

<h3 align="Center">𝑻(𝒏) = 𝒂𝑻 ( ${\frac{𝒏}{𝒃}}$ ) + 𝒇(𝒏)</h3>

<h3>𝑯𝒆𝒓𝒆 𝒂 𝒊𝒔 𝒕𝒉𝒆 𝒏𝒖𝒎𝒃𝒆𝒓 𝒐𝒇 𝒔𝒖𝒃𝒑𝒓𝒐𝒃𝒍𝒆𝒎𝒔 , `𝒏` 𝒊𝒔 𝒕𝒉𝒆 𝒔𝒊𝒛𝒆 𝒐𝒇 𝒕𝒉𝒆 
𝒑𝒓𝒐𝒃𝒍𝒆𝒎, ` $\frac{𝒏}{𝒃}$ ` 𝒊𝒔 𝒕𝒉𝒆 𝒔𝒊𝒛𝒆 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒖𝒃𝒑𝒓𝒐𝒃𝒍𝒆𝒎, 𝒂𝒏𝒅 `𝒇(𝒏)` 𝒊𝒔 𝒕𝒉𝒆 𝒄𝒐𝒔𝒕 
𝒐𝒇 𝒘𝒐𝒓𝒌 𝒅𝒐𝒏𝒆 𝒇𝒐𝒓 𝒏𝒐𝒏 − 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒄𝒂𝒍𝒍𝒔, 𝒘𝒉𝒊𝒄𝒉 𝒂𝒄𝒄𝒐𝒖𝒏𝒕𝒔 
𝒇𝒐𝒓 𝒕𝒉𝒆 𝒅𝒊𝒗𝒊𝒔𝒊𝒐𝒏 𝒐𝒇 𝒂 𝒑𝒓𝒐𝒃𝒍𝒆𝒎 𝒊𝒏𝒕𝒐 𝒔𝒖𝒃 𝒑𝒓𝒐𝒃𝒍𝒆𝒎𝒔 𝒂𝒏𝒅 
𝒄𝒐𝒎𝒃𝒊𝒏𝒂𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒓𝒆𝒔𝒖𝒍𝒕𝒔 𝒐𝒇 𝒕𝒉𝒐𝒔𝒆 𝒔𝒖𝒃 𝒑𝒓𝒐𝒃𝒍𝒆𝒎𝒔. </h3>

<h3>𝑺𝒐𝒎𝒆 𝒐𝒇 𝑫𝒊𝒗𝒊𝒅𝒆 𝒂𝒏𝒅 𝑪𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 𝒂𝒓𝒆: 𝑴𝒆𝒓𝒈𝒆 𝑺𝒐𝒓𝒕, 𝑸𝒖𝒊𝒄𝒌 𝑺𝒐𝒓𝒕 , 𝑩𝒊𝒏𝒂𝒓𝒚 𝑺𝒆𝒂𝒓𝒄𝒉 𝒆𝒕𝒄. </h3>

</ul>

</ul>

<br>
<br>

<h1></h1>
<h1 align="Center">𝟐.𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑹𝒆𝒍𝒂𝒕𝒊𝒐𝒏</h1>

<ul>
  

<h2>𝑨.𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏</h2>

<ul>

<h3>𝑨 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂 𝒏𝒐𝒏
− 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆 𝒇𝒐𝒓𝒎𝒖𝒍𝒂(𝒂𝒍𝒔𝒐 𝒄𝒂𝒍𝒍𝒆𝒅 𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎𝒖𝒍𝒂) 𝒕𝒉𝒂𝒕
𝒔𝒂𝒕𝒊𝒔𝒇𝒊𝒆𝒔 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒂𝒍𝒍 𝒓𝒂𝒏𝒈𝒆𝒔 𝒐𝒇 𝒗𝒂𝒍𝒖𝒆𝒔.</h3>
<h3>𝑰𝒕 𝒊𝒔 𝒂 𝒄𝒍𝒐𝒔𝒆𝒅 − 𝒇𝒐𝒓𝒎 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏, 𝒕𝒉𝒂𝒕 𝒊𝒔 𝒂 𝒏𝒐𝒏 − 𝒓𝒆𝒄𝒖𝒓𝒔𝒊𝒗𝒆
𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒐𝒇 𝒏. 𝑺𝒖𝒄𝒉 𝒂 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒕𝒉𝒂𝒕 𝒔𝒂𝒕𝒊𝒔𝒇𝒊𝒆𝒔 𝒂 𝒈𝒊𝒗𝒆𝒏
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂 <ins>𝒈𝒆𝒏𝒆𝒓𝒂𝒍 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏.</ins></h3>
<h3>𝑨 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝒂 𝒈𝒊𝒗𝒆𝒏 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒘𝒊𝒕𝒉 𝒓𝒆𝒔𝒑𝒆𝒄𝒕 𝒕𝒐
𝒊𝒕𝒔 𝒊𝒏𝒊𝒕𝒊𝒂𝒍 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 𝒂𝒏𝒅 𝒕𝒉𝒊𝒔 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒂 <ins>𝒑𝒂𝒓𝒕𝒊𝒄𝒖𝒍𝒂𝒓 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏.</ins></h3>
<h3>𝑺𝒐𝒎𝒆𝒕𝒊𝒎𝒆𝒔 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒎𝒂𝒚 𝒏𝒐𝒕 𝒉𝒂𝒗𝒆 𝒂 𝒄𝒍𝒐𝒔𝒆𝒅
−𝒇𝒐𝒓𝒎 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏.</h3>

 
</ul>

<h2></h2>
<h2>𝑩.𝑨.𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔</h2>
<ul>
  
<h2></h2>
<h2>𝑩.𝟏.𝑮𝒖𝒆𝒔𝒔 𝒂𝒏𝒅 𝑽𝒆𝒓𝒊𝒇𝒚 𝒎𝒆𝒕𝒉𝒐𝒅</h2>

<ul>

<h3><ins>𝑩.𝟏.𝑨.𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins></h3>

<ul>
  
<h3>𝑰𝒕 𝒊𝒔 𝒌𝒏𝒐𝒘𝒏 𝒃𝒚 𝒗𝒂𝒓𝒊𝒐𝒖𝒔 𝒏𝒂𝒎𝒆𝒔 𝒔𝒖𝒄𝒉 𝒂𝒔 𝒈𝒖𝒆𝒔𝒔 𝒂𝒏𝒅 𝒗𝒆𝒓𝒊𝒇𝒚,
𝒈𝒖𝒆𝒔𝒔 𝒂𝒏𝒅 𝒕𝒆𝒔𝒕 , 𝒈𝒖𝒆𝒔𝒔𝒊𝒏𝒈 𝒂𝒏𝒅 𝒄𝒐𝒏𝒇𝒊𝒓𝒎𝒊𝒏𝒈 𝒆𝒕𝒄.</h3>

<h3><ins>𝑮𝒖𝒆𝒔𝒔</ins>: 𝑻𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒊𝒎𝒑𝒐𝒓𝒕𝒂𝒏𝒕 𝒂𝒔𝒑𝒆𝒄𝒕 𝒐𝒇 𝒕𝒉𝒆 𝒈𝒖𝒆𝒔𝒔 − 𝒂𝒏𝒅 −
𝒗𝒆𝒓𝒊𝒇𝒚 𝒕𝒆𝒄𝒉𝒏𝒊𝒒𝒖𝒆 𝒊𝒔 𝒕𝒐 𝒈𝒖𝒆𝒔𝒔 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒃𝒚
𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒏𝒈 𝒕𝒉𝒆 𝒅𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒕 𝒗𝒂𝒍𝒖𝒆𝒔 𝒐𝒇 `𝒏` 𝒕𝒐 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒆 𝒕𝒉𝒆
𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>


<h3><ins>𝑽𝒆𝒓𝒊𝒇𝒚</ins>: 𝑻𝒉𝒆 𝒔𝒆𝒄𝒐𝒏𝒅 𝒑𝒂𝒓𝒕 𝒐𝒇 𝒕𝒉𝒊𝒔 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒔 𝒕𝒐 𝒗𝒆𝒓𝒊𝒇𝒚 𝒕𝒉𝒆
𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒈𝒖𝒆𝒔𝒔𝒆𝒅 𝒊𝒏 𝒕𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒑𝒉𝒂𝒔𝒆. 𝑻𝒉𝒆 𝒗𝒆𝒓𝒊𝒇𝒊𝒄𝒂𝒕𝒊𝒐𝒏
𝒊𝒔 𝒓𝒆𝒒𝒖𝒊𝒓𝒆𝒅 𝒃𝒆𝒄𝒂𝒖𝒔𝒆 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒊𝒔 𝒋𝒖𝒔𝒕 𝒂 𝒈𝒖𝒆𝒔𝒔. 𝑻𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆
,𝒊𝒕 𝒏𝒆𝒆𝒅𝒔 𝒕𝒐 𝒃𝒆 𝒋𝒖𝒔𝒕𝒊𝒇𝒊𝒆𝒅. 𝑻𝒉𝒊𝒔 𝒋𝒖𝒔𝒕𝒊𝒇𝒊𝒄𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒄𝒂𝒓𝒓𝒊𝒆𝒅 𝒐𝒖𝒕
𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒕𝒆𝒄𝒉𝒏𝒊𝒒𝒖𝒆 𝒐𝒇 𝒎𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒂𝒍 𝒊𝒏𝒅𝒖𝒄𝒕𝒊𝒐𝒏.

</ul>

<h3><ins>𝑩.𝟏.𝑩.𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔:</ins></h3>

<ul>

<h3>   ${𝒕_𝒏}$ = $𝒕_{𝒏-1}$ + 𝟐 ; $𝒕_𝟎$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/A.1.Guess-and-verify%20method-Example-1.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </a> </h3>

<h3>   ${𝒕_𝒏}$ = $𝒕_{𝒏-𝟏}$ +  $𝒏^𝟐$ ; $𝒕_𝟏$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/A.2.Guess-and-verify%20method-Example-2.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a> </h3>

<h3>𝑻(𝒏) = 𝟑𝑻 ( $\frac{𝒏}{𝟐}$ ) , 𝑻(𝟏) = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/A.3.Guess-and-verify%20method-Example-3.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟑 </a> </h3>

<h3>𝑻(𝒏) = $\sqrt{𝒏}$ 𝑻( $\sqrt{𝒏}$ ) + 𝒏  → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/A.4.Guess-and-verify%20method-Example-4.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟒 </a> </h3>


</ul>



</ul>

<h2></h2>
<h2>𝑩.𝟐.𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑴𝒆𝒕𝒉𝒐𝒅</h2>

<ul>

<h3>𝑻𝒉𝒆 𝒎𝒆𝒕𝒉𝒐𝒅 𝒐𝒇 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂𝒍𝒔𝒐 𝒄𝒂𝒍𝒍𝒆𝒅 𝒕𝒉𝒆 𝒊𝒕𝒆𝒓𝒂𝒕𝒊𝒐𝒏
𝒎𝒆𝒕𝒉𝒐𝒅.</h3>

![Screenshot (839)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/c6c062b4-b03e-4837-9824-200d7ab601bb)


<h3>𝑻𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒕𝒉𝒆 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅 𝒄𝒂𝒏 𝒃𝒆 𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅
𝒃𝒚 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒓𝒊𝒈𝒉𝒕 − 𝒉𝒂𝒏𝒅 𝒔𝒊𝒅𝒆 𝒐𝒇 𝒕𝒉𝒆
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒕𝒊𝒍𝒍 𝒂 𝒑𝒂𝒕𝒕𝒆𝒓𝒏 𝒊𝒔 𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅.</h3>
<h3><ins>𝑭𝒐𝒓𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑴𝒆𝒕𝒉𝒐𝒅:</ins> 𝑰𝒇 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒊𝒔
𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅 𝒃𝒚 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒇𝒓𝒐𝒎 𝒃𝒂𝒔𝒆 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏
𝒐𝒏𝒘𝒂𝒓𝒅𝒔,𝒊𝒕 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒇𝒐𝒓𝒘𝒂𝒓𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅.</h3>
<h3><ins>𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑴𝒆𝒕𝒉𝒐𝒅:</ins> 𝑰𝒇 𝒕𝒉𝒆 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏
𝒔𝒕𝒂𝒓𝒕𝒔 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒍𝒂𝒔𝒕 𝒕𝒆𝒓𝒎 𝒂𝒏𝒅 𝒑𝒓𝒐𝒄𝒆𝒆𝒅𝒔 𝒕𝒐 𝒕𝒉𝒆 𝒊𝒏𝒊𝒕𝒊𝒂𝒍 𝒕𝒆𝒓𝒎,
𝒊𝒕 𝒊𝒔 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝒕𝒉𝒆 𝒃𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒐𝒓 𝒕𝒉𝒆 𝒃𝒂𝒄𝒌 −
𝒕𝒓𝒂𝒄𝒌𝒊𝒏𝒈 𝒎𝒆𝒕𝒉𝒐𝒅.</h3>
<h3>𝑭𝒐𝒓𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑴𝒆𝒕𝒉𝒐𝒅, 𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑴𝒆𝒕𝒉𝒐𝒅,
𝑩𝒐𝒕𝒉 𝒐𝒇 𝒕𝒉𝒆 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒊𝒏𝒗𝒐𝒍𝒗𝒆 𝒕𝒘𝒐 𝒔𝒕𝒆𝒑𝒔,
𝒘𝒉𝒊𝒄𝒉 𝒄𝒂𝒏 𝒊𝒏𝒇𝒐𝒓𝒎𝒂𝒍𝒍𝒚 𝒃𝒆 𝒘𝒓𝒊𝒕𝒕𝒆𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>
<ul>
  
<h3><ins>𝑷𝒍𝒖𝒈 ∶</ins> 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒆 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅𝒍𝒚</h3>
<h3><ins>𝑪𝒉𝒖𝒈:</ins> 𝒔𝒊𝒎𝒑𝒍𝒊𝒇𝒚 𝒕𝒉𝒆 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒊𝒐𝒏𝒔</h3>

</ul>  

<h3>𝑷𝒍𝒖𝒈 𝒊𝒔 𝒔𝒊𝒎𝒑𝒍𝒆. 𝑶𝒏𝒆 𝒉𝒂𝒔 𝒕𝒐 𝒌𝒆𝒆𝒑 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒏𝒈 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅𝒍𝒚.</h3>
<h3>𝑪𝒉𝒖𝒈 𝒊𝒔 𝒂 𝒔𝒕𝒆𝒑 𝒐𝒇 𝒔𝒊𝒎𝒑𝒍𝒊𝒇𝒚𝒊𝒏𝒈 𝒕𝒉𝒆 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒊𝒐𝒏𝒔.
𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒎𝒂𝒚 𝒃𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒆𝒅 𝒃𝒚 𝒗𝒆𝒓𝒊𝒇𝒊𝒄𝒂𝒕𝒊𝒐𝒏
𝒖𝒔𝒊𝒏𝒈 𝒎𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒂𝒍 𝒊𝒏𝒅𝒖𝒄𝒕𝒊𝒐𝒏.</h3>

<ul>

<h2></h2>
<h2>𝑩.𝑨.𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏</h2>

<ul>

<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins>𝑻𝒉𝒊𝒔 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒔 𝒂𝒍𝒔𝒐 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝒕𝒉𝒆 𝒃𝒂𝒄𝒌𝒕𝒓𝒂𝒄𝒌𝒊𝒏𝒈 𝒎𝒆𝒕𝒉𝒐𝒅
𝒐𝒓 𝒕𝒉𝒆 𝒃𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝒊𝒕𝒆𝒓𝒂𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅.</h3>
<h3>𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒔𝒕𝒂𝒓𝒕𝒔 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒍𝒂𝒔𝒕 𝒕𝒆𝒓𝒎( $𝒕_𝒏$ ) 𝒐𝒇
𝒂 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒂𝒏𝒅 𝒎𝒐𝒗𝒆𝒔 𝒕𝒐𝒘𝒂𝒓𝒅𝒔 𝒕𝒉𝒆 𝒃𝒂𝒔𝒆 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 ( $𝒕_𝟎$ )
𝒃𝒚 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅𝒍𝒚 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒏𝒈 𝒕𝒉𝒆 𝒓𝒊𝒈𝒉𝒕 − 𝒉𝒂𝒏𝒅 𝒔𝒊𝒅𝒆 𝒐𝒇 𝒂
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝑻𝒉𝒆 𝒑𝒓𝒐𝒄𝒆𝒔𝒔 𝒊𝒔 𝒄𝒐𝒏𝒕𝒊𝒏𝒖𝒆𝒅 𝒕𝒊𝒍𝒍 𝒕𝒉𝒆 𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎 𝒊𝒔 𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅,
𝒘𝒉𝒊𝒄𝒉 𝒄𝒂𝒏 𝒃𝒆 𝒄𝒐𝒏𝒇𝒊𝒓𝒎𝒆𝒅 𝒃𝒚 𝒕𝒉𝒆 𝒐𝒃𝒔𝒆𝒓𝒗𝒂𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒐𝒎𝒎𝒐𝒏
𝒑𝒂𝒕𝒕𝒆𝒓𝒏 𝒕𝒉𝒂𝒕 𝒆𝒎𝒆𝒓𝒈𝒆𝒔 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒑𝒓𝒐𝒄𝒆𝒔𝒔 𝒐𝒇 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅
𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏.</h3>

<ul>

<h2></h2>
<h2>𝑩.𝑨.𝟏.𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>

<h3>$𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟑 , $𝒕_𝟏$ = 𝟒 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.1.Backward%20Substitution(Example%20-1).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </a></h3>

<h3>$𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟎. 𝟎𝟑 $𝒕_{𝒏−𝟏}$ , $𝒕_𝟎$ = 𝟏𝟎𝟎 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.2.Backward%20Substitution(Example%20-2).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>

<h3>$𝒕_𝒏$ = 𝒏 $𝒕_{𝒏−𝟏}$ 𝒇𝒐𝒓 𝒏 > 𝟏 , $𝒕_𝟎$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.3.Backward%20Substitution(Example%20-3).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟑 </a></h3>

<h3>$𝒕_𝒏$ = 𝟕 $𝒕_{𝒏−𝟏}$  , $𝒕_𝟎$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.4.Backward%20Substitution(Example%20-4).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟒 </a></h3>


<ul>

<h2></h2>
<h2>𝑩.𝑨.𝟐.𝑩𝒂𝒄𝒌𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3> 𝑻𝒉𝒆𝒐𝒓𝒆𝒎: $𝒕_𝒏$ = 𝒓 $𝒕_{𝒏−𝟏}$ , 𝒏 > 𝟎 , $𝒕_𝟎$ = 𝜶 , 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒊𝒔 𝒈𝒊𝒗𝒆𝒏 𝒂𝒔 $𝒕_𝒏$ = 𝜶 $𝒓^𝒏$ → 
  <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.5.Theorem%20on%20Backward%20Substitution%20Method.pdf">𝑻𝒉𝒆𝒐𝒓𝒆𝒎 & 𝑷𝒓𝒐𝒐𝒇-𝑫𝒆𝒕𝒂𝒊𝒍𝒔 </a></h3>

  

</ul>
</ul>

<h2></h2>

<h3> $𝒕_𝒏$ = 𝒌 $𝒕_{𝒏−𝟏}$ 𝒇𝒐𝒓 𝒏 ≥ 𝟎 , $𝒕_𝟑$ = 𝟑𝟒𝟑 , $𝒕_𝟒$ = 𝟐𝟒𝟎𝟏 𝒂𝒏𝒅 $𝒕_𝟎$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.A.6.Backward%20Substitution(Example-6(Based%20on%20Theorem)).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟓 (𝑩𝒂𝒔𝒆𝒅 𝒐𝒏 𝒕𝒉𝒆𝒐𝒓𝒆𝒎) </a></h3>



</ul>

</ul>

<h2></h2>
<h2>𝑩.𝑩.𝑭𝒐𝒓𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏</h2>

<ul>
  
<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins> 𝑻𝒉𝒆 𝒇𝒐𝒓𝒘𝒂𝒓𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅(𝒐𝒓 𝒇𝒐𝒓𝒘𝒂𝒓𝒅 𝒊𝒕𝒆𝒓𝒂𝒕𝒊𝒐𝒏
𝒎𝒆𝒕𝒉𝒐𝒅) 𝒊𝒔 𝒂 𝒎𝒆𝒕𝒉𝒐𝒅 𝒐𝒇 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏
𝒃𝒚 𝒓𝒆𝒑𝒆𝒂𝒕𝒆𝒅 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝒊𝒕𝒔 𝒕𝒆𝒓𝒎𝒔. 𝑻𝒉𝒆 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏
𝒔𝒕𝒂𝒓𝒕𝒔 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒃𝒂𝒔𝒆 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏( $𝒕_𝟎$ ) 𝒂𝒏𝒅 𝒄𝒐𝒏𝒕𝒊𝒏𝒖𝒆𝒔 𝒕𝒊𝒍𝒍 𝒕𝒉𝒆
𝒇𝒊𝒏𝒂𝒍 𝒕𝒆𝒓𝒎( $𝒕_𝒏$ ) 𝒊𝒔 𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅.</h3>

<ul>

<h2></h2>
<h2>𝑩.𝑩.𝟏.𝑭𝒐𝒓𝒘𝒂𝒓𝒅 𝑺𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>

<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ +𝟑 ,  $𝒕_𝟎$ = 𝟒 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.1.Forward%20Substitution(Example-1).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏  </a></h3>

<h3>$𝒕_𝒏$ = 𝒏 $𝒕_{𝒏−𝟏}$ 𝒇𝒐𝒓 𝒏 ≥ 𝟏 , $𝒕_𝟎$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.2.Forward%20Substitution(Example-2).pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>

</ul>
</ul>

</ul>
</ul>
</ul>

<h2></h2>
<h2>𝑪.𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 − 𝑻𝒓𝒆𝒆 𝑴𝒆𝒕𝒉𝒐𝒅</h2>

<ul>


<h3>𝑻𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 − 𝒕𝒓𝒆𝒆 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒔 𝒂𝒏𝒐𝒕𝒉𝒆𝒓 𝒘𝒂𝒚 𝒐𝒇 𝒔𝒐𝒍𝒗𝒊𝒏𝒈
𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒃𝒚 𝒆𝒙𝒑𝒂𝒏𝒅𝒊𝒏𝒈 𝒊𝒕𝒔 𝒕𝒆𝒓𝒎𝒔 𝒊𝒏 𝒂
𝒕𝒓𝒆𝒆 − 𝒍𝒊𝒌𝒆 𝒎𝒂𝒏𝒏𝒆𝒓.</h3>

<h3>𝑰𝒕 𝒊𝒔 𝒂𝒍𝒎𝒐𝒔𝒕 𝒔𝒊𝒎𝒊𝒍𝒂𝒓 𝒕𝒐 𝒕𝒉𝒆 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅, 𝒃𝒖𝒕 𝒊𝒔
𝒂 𝒗𝒊𝒔𝒖𝒂𝒍 𝒎𝒆𝒕𝒉𝒐𝒅. 𝑰𝒕 𝒊𝒔 𝒖𝒔𝒆𝒅 𝒇𝒐𝒓 𝒐𝒃𝒕𝒂𝒊𝒏𝒊𝒏𝒈 𝒕𝒉𝒆
𝒂𝒔𝒚𝒎𝒑𝒕𝒐𝒕𝒊𝒄 𝒃𝒐𝒖𝒏𝒅𝒔.</h3>

<h3>𝑻𝒉𝒆 𝒔𝒕𝒆𝒑𝒔 𝒊𝒏𝒗𝒐𝒍𝒗𝒆𝒅 𝒊𝒏 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏
𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 − 𝒕𝒓𝒆𝒆 𝒎𝒆𝒕𝒉𝒐𝒅 𝒂𝒓𝒆 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<ul>

<h3>𝟏. 𝑭𝒐𝒓𝒎𝒖𝒍𝒂𝒕𝒆 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒃𝒚 𝒗𝒊𝒔𝒖𝒂𝒍𝒊𝒛𝒊𝒏𝒈
𝒕𝒉𝒆 𝒄𝒂𝒍𝒍𝒔 𝒂𝒔 𝒂 𝒕𝒓𝒆𝒆.</h3>

<h3>𝟐. 𝑪𝒐𝒍𝒍𝒆𝒄𝒕 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒊𝒏𝒇𝒐𝒓𝒎𝒂𝒕𝒊𝒐𝒏 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒕𝒓𝒆𝒆:</h3>

<ul>

<h3><ins>𝒂)𝑳𝒆𝒗𝒆𝒍:</ins> 𝑫𝒆𝒕𝒆𝒓𝒎𝒊𝒏𝒆 𝒕𝒉𝒆 𝒍𝒆𝒗𝒆𝒍 𝒐𝒇 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒆𝒅 𝒕𝒓𝒆𝒆.
𝑻𝒉𝒆 𝒍𝒆𝒗𝒆𝒍 𝒐𝒇 𝒂 𝒏𝒐𝒅𝒆 𝒊𝒔 𝒕𝒉𝒆 𝒍𝒆𝒏𝒈𝒕𝒉 𝒐𝒇 𝒕𝒉𝒆 𝒑𝒂𝒕𝒉 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆
𝒓𝒐𝒐𝒕 𝒕𝒐 𝒕𝒉𝒆 𝒏𝒐𝒅𝒆. 𝑻𝒉𝒆 𝒍𝒆𝒗𝒆𝒍 𝒐𝒇 𝒂 𝒓𝒐𝒐𝒕 𝒊𝒔 𝟎.𝑻𝒉𝒆 𝒍𝒆𝒗𝒆𝒍 𝒐𝒇 𝒂 𝒕𝒓𝒆𝒆 𝒊𝒏𝒅𝒊𝒄𝒂𝒕𝒆𝒔 𝒕𝒉𝒆 𝒏𝒖𝒎𝒃𝒆𝒓 𝒐𝒇 𝒔𝒖𝒃𝒑𝒓𝒐𝒃𝒍𝒆𝒎𝒔
𝒂𝒏𝒅 𝒂𝒎𝒐𝒖𝒏𝒕 𝒐𝒇 𝒘𝒐𝒓𝒌 𝒅𝒐𝒏𝒆 𝒂𝒕 𝒆𝒗𝒆𝒓𝒚 𝒍𝒆𝒗𝒆𝒍.</h3>

<h3><ins>𝒃) 𝑪𝒐𝒔𝒕 𝒑𝒆𝒓 𝒍𝒆𝒗𝒆𝒍:</ins>  𝑪𝒐𝒔𝒕 𝒑𝒆𝒓 𝒍𝒆𝒗𝒆𝒍 𝒉𝒂𝒔 𝒕𝒐 𝒃𝒆 𝒄𝒂𝒍𝒄𝒖𝒍𝒂𝒕𝒆𝒅 𝒇𝒐𝒓
𝒆𝒗𝒆𝒓𝒚 𝒍𝒆𝒗𝒆𝒍 𝒐𝒇 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒆𝒅 𝒕𝒓𝒆𝒆 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒍𝒆𝒗𝒆𝒍 𝒄𝒐𝒖𝒏𝒕
𝒂𝒏𝒅 𝒕𝒉𝒆 𝒂𝒎𝒐𝒖𝒏𝒕 𝒐𝒇 𝒘𝒐𝒓𝒌 𝒅𝒐𝒏𝒆 𝒃𝒚 𝒕𝒉𝒆 𝒔𝒖𝒃𝒑𝒓𝒐𝒃𝒍𝒆𝒎𝒔.</h3> 


<h3><ins>𝒄)𝑻𝒐𝒕𝒂𝒍 𝑪𝒐𝒔𝒕:</ins> 𝑰𝒕 𝒊𝒔 𝒕𝒉𝒆 𝒔𝒖𝒎 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒐𝒔𝒕 𝒐𝒇 𝒂𝒍𝒍 𝒍𝒆𝒗𝒆𝒍𝒔.</h3> 


</ul>

<h3>𝟑.𝑬𝒙𝒑𝒓𝒆𝒔𝒔 𝒕𝒉𝒆 𝒄𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝒊𝒏 𝒕𝒆𝒓𝒎𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒕𝒐𝒕𝒂𝒍 𝒄𝒐𝒔𝒕.</h3>

<h3>𝟒. 𝑽𝒆𝒓𝒊𝒇𝒚 𝒕𝒉𝒆 𝒔𝒖𝒎𝒎𝒂𝒕𝒊𝒐𝒏 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒎𝒆𝒕𝒉𝒐𝒅 𝒐𝒇 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏
𝒐𝒓 𝒔𝒐𝒎𝒆 𝒐𝒕𝒉𝒆𝒓 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒇 𝒏𝒆𝒄𝒆𝒔𝒔𝒂𝒓𝒚.</h3>

<h2></h2>
<h2>𝑪.𝑨.𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 − 𝑻𝒓𝒆𝒆 𝑴𝒆𝒕𝒉𝒐𝒅-𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>

<h3> 𝑻(𝒏) = 𝟐𝑻 ( $\frac{𝒏}{𝟐}$ ) + 𝒏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/C.1.Recurrence-Tree%20Method(%20Example%201).pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 (𝑴𝒆𝒓𝒈𝒆 𝑺𝒐𝒓𝒕)</a></h3>

<h3> $𝒕_𝒏$ = $𝒕_{𝒏-𝟏}$ + 𝒂 ,𝒇𝒐𝒓 𝒏 > 𝟏 𝒂𝒏𝒅 $𝒕_𝒏$ = 𝟏 ,𝒇𝒐𝒓 𝒏 =  𝟏 . 𝑭𝒊𝒏𝒅 𝒂𝒔𝒚𝒎𝒑𝒕𝒐𝒕𝒊𝒄 𝒄𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝒐𝒇 𝒕𝒉𝒆 𝒕𝒓𝒆𝒆 𝒇𝒐𝒓 𝒂 = 𝟏 𝒂𝒏𝒅 𝒂 = 𝒏 →
 <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/C.2.Recurrence-Tree%20Method(%20Example%202).pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>

<h3> $𝒕_𝒏$ = 𝟖𝑻 ( $\frac{𝒏}{𝟐}$) , 𝒇𝒐𝒓 𝒏 > 𝟏 𝒂𝒏𝒅 $𝒕_𝒏$ = 𝟏 ,𝒇𝒐𝒓 𝒏 =  𝟏 . (𝑨𝒏 𝒂𝒍𝒕𝒆𝒓𝒏𝒂𝒕𝒊𝒗𝒆 𝒘𝒂𝒚 𝒂𝒍𝒔𝒐 𝒅𝒊𝒔𝒄𝒖𝒔𝒔𝒆𝒅)→ <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/C.3.Recurrence-Tree%20Method(%20Example%203).pdf">   𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟑 </a></h3> </h3>

</ul>


</ul>




</ul>

<h2></h2>
<h2>𝑫.𝑫𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝑴𝒆𝒕𝒉𝒐𝒅</h2>

<ul>

<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins></h3>

<ul>

<h3>𝑻𝒉𝒊𝒔 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒔 𝒂𝒍𝒔𝒐 𝒌𝒏𝒐𝒘𝒏 𝒂𝒔 𝒕𝒉𝒆 𝒍𝒂𝒅𝒅𝒆𝒓 𝒎𝒆𝒕𝒉𝒐𝒅 ,
𝒔𝒖𝒎𝒎𝒂𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅 𝒐𝒓 𝒕𝒆𝒍𝒆𝒔𝒄𝒐𝒑𝒊𝒏𝒈 𝒎𝒆𝒕𝒉𝒐𝒅.</h3>
<h3>𝑰𝒕 𝒉𝒆𝒍𝒑𝒔 𝒔𝒐𝒍𝒗𝒆 𝒂 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏 𝒘𝒊𝒕𝒉 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕
𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒔 , 𝒘𝒉𝒊𝒄𝒉 𝒊𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒐𝒓𝒎 $𝒕_𝒏$ − $𝒕_{𝒏−𝟏}$ = 𝒄, 𝒘𝒉𝒆𝒓𝒆
𝒄 𝒊𝒔 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕.</h3>
<h3>𝑻𝒉𝒖𝒔, 𝒐𝒏𝒆 𝒄𝒂𝒏 𝒓𝒆𝒂𝒓𝒓𝒂𝒏𝒈𝒆 𝒕𝒉𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒂𝒏𝒅 𝒔𝒖𝒎 𝒊𝒕.
𝑻𝒉𝒊𝒔 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒕𝒆𝒍𝒆𝒔𝒄𝒐𝒑𝒊𝒏𝒈 .</h3>


</ul>

<h2></h2>
<h2>𝑫.𝑨.𝑫𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝑴𝒆𝒕𝒉𝒐𝒅-𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>

<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟒 𝒘𝒊𝒕𝒉 $𝒕_𝟏$ = 𝟐 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/D.1.Difference%20Method(Example%201).pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </a></h3>

<h3> $𝒕_𝒏$ = $𝒕_{𝒏−𝟏}$ + 𝟔𝒏, 𝒏 ≥ 𝟏 𝒂𝒏𝒅 $𝒕_𝟏$ = 𝟔 , 𝒂𝒏𝒅 𝒇𝒊𝒏𝒅 𝒕𝒉𝒆 𝒕𝒆𝒓𝒎 $𝒕_{𝟒𝟎}$ → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/D.2.Difference%20Method(Example%202).pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>




</ul>

<h3>𝑻𝒉𝒆 𝒂𝒇𝒐𝒓𝒆𝒎𝒆𝒏𝒕𝒊𝒐𝒏𝒆𝒅 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒂𝒓𝒆 𝒖𝒔𝒆𝒇𝒖𝒍 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈
𝒇𝒊𝒓𝒔𝒕 − 𝒐𝒓𝒅𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒂𝒏𝒅 𝒂𝒓𝒆 𝒏𝒐𝒕
𝒔𝒖𝒊𝒕𝒂𝒃𝒍𝒆 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒉𝒊𝒈𝒉𝒆𝒓 𝒐𝒓𝒅𝒆𝒓.
𝑯𝒊𝒈𝒉𝒆𝒓 − 𝒐𝒓𝒅𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒂𝒓𝒆 𝒔𝒐𝒍𝒗𝒆𝒅 𝒃𝒚
𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝒓𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅 .</h3>




</ul>


<h2></h2>
<h2>𝑬.𝑷𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝑹𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏</h2>

<ul>
  
<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins></h3>

<ul>

<h3>𝑺𝒐, 𝒇𝒂𝒓 ,𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 𝒉𝒂𝒗𝒆 𝒃𝒆𝒆𝒏 𝒔𝒐𝒍𝒗𝒆𝒅 𝒖𝒔𝒊𝒏𝒈
𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒔𝒖𝒄𝒉 𝒂𝒔 𝒈𝒖𝒆𝒔𝒔 𝒂𝒏𝒅 𝒗𝒆𝒓𝒊𝒇𝒚, 𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏, 𝒂𝒏𝒅
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒕𝒓𝒆𝒆.</h3>

<h3>𝑯𝒐𝒘𝒆𝒗𝒆𝒓 𝒕𝒉𝒆𝒔𝒆 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒂𝒓𝒆 𝒏𝒐𝒕 𝒖𝒔𝒆𝒇𝒖𝒍 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒂 𝒉𝒊𝒈𝒉𝒆𝒓 𝒐𝒓𝒅𝒆𝒓, 𝒇𝒐𝒓 𝒘𝒉𝒊𝒄𝒉
𝒕𝒉𝒆 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝒓𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅 𝒊𝒔 𝒖𝒔𝒆𝒅.</h3>


<h3>𝑻𝒉𝒆 𝒊𝒅𝒆𝒂 𝒊𝒔 𝒕𝒐 𝒓𝒆𝒅𝒖𝒄𝒆 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒕𝒐
𝒂 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒏𝒅 𝒆𝒙𝒑𝒓𝒆𝒔𝒔 𝒊𝒕𝒔 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏
𝒊𝒏 𝒕𝒆𝒓𝒎𝒔 𝒐𝒇 𝒊𝒕𝒔 𝒓𝒐𝒐𝒕𝒔.</h3>


<h3>𝑨 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒐𝒓𝒅𝒆𝒓 `𝒌` 𝒄𝒂𝒏
𝒃𝒆 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒅 𝒊𝒏 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒇𝒐𝒓𝒎:</h3>

<h3 align="Center"> $𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝟏}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝒌}$ = 𝟎 </h3>

<h3>𝑻𝒉𝒊𝒔 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒍𝒊𝒏𝒆𝒂𝒓 𝒃𝒆𝒄𝒂𝒖𝒔𝒆 𝒊𝒕 𝒅𝒐𝒆𝒔 𝒏𝒐𝒕 𝒊𝒏𝒗𝒐𝒍𝒗𝒆
𝒂𝒏𝒚 𝒔𝒒𝒖𝒂𝒓𝒆, 𝒔𝒒𝒖𝒂𝒓𝒆 𝒓𝒐𝒐𝒕, 𝒐𝒓 𝒄𝒖𝒃𝒊𝒄 𝒕𝒆𝒓𝒎𝒔.</h3>

<h3>𝑰𝒏 𝒂𝒅𝒅𝒊𝒕𝒊𝒐𝒏, 𝒕𝒉𝒆 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒕𝒉𝒊𝒔 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒔 `𝒌`
𝒂𝒔 𝒕𝒉𝒆 𝒅𝒊𝒇𝒇𝒆𝒓𝒆𝒏𝒄𝒆 𝒃𝒆𝒕𝒘𝒆𝒆𝒏 𝒕𝒉𝒆 𝒉𝒊𝒈𝒉𝒆𝒔𝒕 𝒂𝒏𝒅 𝒕𝒉𝒆 𝒔𝒎𝒂𝒍𝒍𝒆𝒔𝒕
𝒔𝒖𝒇𝒇𝒊𝒙 𝒊𝒔 ∶</h3>

<br>
<br>

<img align="Center" src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/ae2e2c38-1c85-4fe4-bca6-f5a3698e2de4" width=300 height=150>


<h3>𝑻𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒂𝒓𝒆 𝒕𝒉𝒆 𝒔𝒕𝒆𝒑𝒔 𝒊𝒏𝒗𝒐𝒍𝒗𝒆𝒅 𝒊𝒏 𝒕𝒉𝒆 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍
𝒓𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒑𝒓𝒐𝒄𝒆𝒅𝒖𝒓𝒆 𝒖𝒔𝒆𝒅 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>

<ul>

<h3>𝟏. 𝑭𝒐𝒓𝒎 𝒂 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒈𝒊𝒗𝒆𝒏
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝟐. 𝑭𝒊𝒏𝒅 𝒕𝒉𝒆 𝒓𝒐𝒐𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝟑. 𝑭𝒊𝒏𝒅 𝒂 𝒈𝒆𝒏𝒆𝒓𝒂𝒍 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒘𝒊𝒕𝒉 𝒖𝒏𝒌𝒏𝒐𝒘𝒏 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒔.</h3>
<h3>𝟒. 𝑺𝒐𝒍𝒗𝒆 𝒕𝒉𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒘𝒊𝒕𝒉 𝒓𝒆𝒔𝒑𝒆𝒄𝒕 𝒕𝒐 𝒕𝒉𝒆 𝒊𝒏𝒊𝒕𝒊𝒂𝒍
𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏𝒔 𝒕𝒐 𝒈𝒆𝒕 𝒂 𝒔𝒑𝒆𝒄𝒊𝒇𝒊𝒄 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏.</h3>


</ul>
</ul>

<h3><ins>𝑷𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝑹𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏−𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔</ins></h3>

<ul>

<h3>𝑻𝒐 𝒔𝒐𝒍𝒗𝒆 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒖𝒔𝒊𝒏𝒈 𝒕𝒉𝒆 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍
𝒓𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒎𝒆𝒕𝒉𝒐𝒅, 𝒕𝒉𝒆 𝒇𝒊𝒓𝒔𝒕 𝒔𝒕𝒆𝒑 𝒊𝒔 𝒕𝒐 𝒇𝒐𝒓𝒎𝒖𝒍𝒂𝒕𝒆 𝒕𝒉𝒆
𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>

<h3>𝑻(𝒏) = $𝒂_𝟏$ 𝑻(𝒏 − 𝟏) + $𝒂_𝟐$ 𝑻(𝒏 − 𝟐) </h3>

<h3>𝑳𝒆𝒕 𝒖𝒔 𝒓𝒆 − 𝒂𝒓𝒓𝒂𝒏𝒈𝒆 𝒕𝒉𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3>𝑻(𝒏)-  $𝒂_𝟏$ 𝑻(𝒏 − 𝟏) -  $𝒂_𝟐$ 𝑻(𝒏 − 𝟐) = 𝟎</h3>

<h3>𝑳𝒆𝒕 𝑻(𝒏) = $𝒙^𝒏$</h3>

<h3>∴ 𝑻(𝒏 − 𝟏) = $𝒙^{𝒏−𝟏}$ 𝒂𝒏𝒅 𝑻(𝒏 − 𝟐) = $𝒙^𝒏−𝟐$ </h3>

<h3>𝑻𝒉𝒊𝒔 𝒈𝒊𝒗𝒆𝒔 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>

<h3>$𝒙^𝒏$ + $𝒂_𝟏$ $𝒙^{𝒏−𝟏}$ + $𝒂_𝟐$ $𝒙^{𝒏−𝟐}$ =𝟎 </h3>

<h3>𝑨𝒔 𝒙 ≠ 𝟎, 𝒅𝒊𝒗𝒊𝒅𝒆 𝒕𝒉𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒕𝒐 𝒈𝒆𝒕 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈
𝒓𝒆𝒂𝒍𝒕𝒊𝒐𝒏:</h3>

<h3>⇒ $\frac{𝒙^𝒏}{𝒙^𝒏−𝟐}$ + 𝒂𝟏 × $\frac{𝒙^𝒏−𝟏}{𝒙^𝒏−𝟐}$ + 𝒂𝟐 × $\frac{𝒙^𝒏−𝟐}{𝒙^𝒏−𝟐}$ =𝟎 </h3>

<h3>⇒ $𝒙^{𝒏−(𝒏−𝟐)}$ + 𝒂𝟏 × $𝒙^{𝒏−𝟏−(𝒏−𝟐)}$ + 𝒂𝟐 × $𝒙^{𝒏−𝟐−(𝒏−𝟐)}$ =𝟎 </h3>

<h3>⇒ $𝒙^𝟐$ + $𝒂_𝟏$ 𝒙 + $𝒂_𝟐$ = 𝟎</h3>

<h3>𝑻𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆 𝒊𝒕 𝒄𝒂𝒏 𝒃𝒆 𝒐𝒃𝒔𝒆𝒓𝒗𝒆𝒅 𝒕𝒉𝒂𝒕 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒕𝒓𝒂𝒏𝒔𝒇𝒐𝒓𝒎𝒆𝒅 𝒊𝒏𝒕𝒐 𝒂 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏,
𝒘𝒉𝒊𝒄𝒉 𝒊𝒔 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3>𝑻(𝒏) − $𝒂_𝟏$ 𝑻(𝒏 − 𝟏) − $𝒂_𝟐$ 𝑻(𝒏 − 𝟐) =𝟎</h3>


<img align="Center" src="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/73af7498-07d8-415a-9040-e57fdb481fd7" width=350 height=100>



<h3>⟹ $𝒙^𝟐$ + $𝒂_𝟏$ 𝒙 + $𝒂_𝟐$ = 𝟎</h3>


<h3>𝑻𝒉𝒆 𝒐𝒓𝒅𝒆𝒓 𝒐𝒇 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝟐;𝒕𝒉𝒆𝒓𝒆𝒇𝒐𝒓𝒆, 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂𝒍𝒔𝒐 𝒐𝒇 𝒐𝒓𝒅𝒆𝒓 𝟐.</h3>

<h3>𝑶𝒏𝒆 𝒄𝒂𝒏 𝒈𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆 𝒕𝒉𝒊𝒔 𝒊𝒏 𝒕𝒉𝒆 𝒇𝒐𝒓𝒎 𝒂 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒇𝒐𝒓 𝒕𝒉𝒆
𝒄𝒐𝒏𝒗𝒆𝒓𝒔𝒊𝒐𝒏 𝒐𝒇 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒏𝒕𝒐 𝒕𝒉𝒆
𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>


<h3>𝑻𝒉𝒆𝒐𝒓𝒆𝒎 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.2.Polynomial%20Reduction-Solving%20Homogeneous%20Equations-Theorem.pdf">𝑻𝒉𝒆𝒐𝒓𝒆𝒎 𝑩𝒂𝒔𝒆𝒅 𝒐𝒏 𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔
𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 − 𝑷𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝑹𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏. </a></h3>

<h3>𝑻𝒉𝒓𝒆𝒆 𝒄𝒂𝒔𝒆𝒔 𝒆𝒙𝒊𝒔𝒕𝒔 𝒇𝒐𝒓 𝒇𝒊𝒏𝒅𝒊𝒏𝒈 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 𝒃𝒂𝒔𝒆𝒅 𝒐𝒏 𝒕𝒉𝒆 𝒓𝒐𝒐𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏, 𝒘𝒉𝒐 𝒂𝒓𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<ul>

<h3>𝑪𝒂𝒔𝒆 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.3.Polynomial%20Reduction-Solving%20Homogeneous%20Equations-Case1.pdf">𝑪𝒂𝒔𝒆 𝟏: −𝒓𝒐𝒐𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒓𝒆 𝒅𝒊𝒔𝒕𝒊𝒏𝒄𝒕. </a></h3>

<h3>𝑪𝒂𝒔𝒆 𝟐 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.3.Polynomial%20Reduction-Solving%20Homogeneous%20Equations-Case2.pdf">𝑪𝒂𝒔𝒆 𝟐: −𝒓𝒐𝒐𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒓𝒆 𝒏𝒐𝒕 𝒅𝒊𝒔𝒕𝒊𝒏𝒄𝒕. </a></h3>

<h3>𝑪𝒂𝒔𝒆 𝟑 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.3.Polynomial%20Reduction-Solving%20Homogeneous%20Equations-Case3.pdf">𝑪𝒂𝒔𝒆 𝟑 − 𝒓𝒐𝒐𝒕𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒂𝒓𝒆
𝒅𝒊𝒔𝒕𝒊𝒏𝒄𝒕 𝒃𝒖𝒕 𝒄𝒐𝒎𝒑𝒍𝒆𝒙. </a></h3>


</ul>

<h2></h2>
<h2>𝑬.𝑨.𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏-𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>

<h3> $𝒕_𝒏$ − 𝟑 $𝒕_{𝒏−𝟏}$ + 𝟐 $𝒕_{𝒏−𝟐}$ = 𝟎 𝒇𝒐𝒓 𝒏 > 𝟎 , $𝒕_𝟎$ = 𝟎 , $𝒕_𝟏$ = 𝟏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.A.Polynomial%20Reduction%20Method-Homogeneous%20Equations-Eg-1.pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </a></h3>

<h3> $𝒕_𝒏$ − 𝟏𝟏 $𝒕_{𝒏−𝟏}$ + 𝟑𝟎 $𝒕_{𝒏−𝟐}$ = 𝟎 ; $𝒕_𝟎$ = 𝟎 , $𝒕_𝟏$ = 𝟏 , $𝒕_𝟐$ = 𝟐 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.A.Polynomial%20Reduction%20Method-Homogeneous%20Equations-Eg-2.pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>

<h3> $𝒕_𝒏$ − 𝟓 $𝒕_{𝒏−𝟏}$ + 𝟖 $𝒕_{𝒏−𝟐}$ − 𝟒 $𝒕_{𝒏−𝟑}$ = 𝟎 𝒇𝒐𝒓 𝒏 > 𝟎 , $𝒕_𝟎$ = 𝟎 , $𝒕_𝟏$ = 𝟏, $𝒕_𝟐$ = 𝟐
 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.A.Polynomial%20Reduction%20Method-Homogeneous%20Equations-Eg-3.pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </a></h3>



</ul> 


</ul>

<h3><ins>𝑷𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 𝑹𝒆𝒅𝒖𝒄𝒕𝒊𝒐𝒏 −𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑵𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔</ins></h3>

<ul>

<h3>𝑭𝒐𝒓 𝒂 𝒏𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏, 𝒇(𝒏) 𝒊𝒔 𝒏𝒐𝒕 𝒛𝒆𝒓𝒐
𝒊𝒏 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒍 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏. 𝑯𝒆𝒏𝒄𝒆, 𝒕𝒉𝒆 𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄
𝒏𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒇𝒐𝒓𝒎 𝒄𝒂𝒏 𝒃𝒆 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒅 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>



<h3 align="Center"> $𝒂_𝟎$ $𝒕_𝒏$ + $𝒂_𝟏$ $𝒕_{𝒏−𝒌}$ + ⋯ + $𝒂_𝒌$ $𝒕_{𝒏−𝟏}$ = $𝒃^𝒏$ 𝒑(𝒏) </h3>

<h3>𝑯𝒆𝒓𝒆 𝒃 𝒊𝒔 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒂𝒏𝒅 𝒑(𝒏) 𝒊𝒔 𝒂 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍 . 𝑻𝒉𝒆
𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒔𝒕𝒊𝒄 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒊𝒔 𝒄𝒂𝒏 𝒃𝒆 𝒘𝒓𝒊𝒕𝒕𝒆𝒏 𝒂𝒔
𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<h3 align="Center"> ( $𝒂_𝟎$ $𝒓^𝒌$ $𝒂_𝟏$ $𝒓^{𝒌−𝟏}$ + $𝒂_𝟏$ $𝒓^{𝒌−𝟏}$ + ⋯ + $𝒂_𝒌$) $(𝒓 − 𝒃)^{𝒅+𝟏}$ = 𝟎 </h3>

<h3>𝑯𝒆𝒓𝒆 `𝒅` 𝒊𝒔 𝒕𝒉𝒆 𝒅𝒆𝒈𝒓𝒆𝒆 𝒐𝒇 𝒕𝒉𝒆 𝒑𝒐𝒍𝒚𝒏𝒐𝒎𝒊𝒂𝒍.</h3>
<h3>𝑻𝒉𝒆 𝒔𝒕𝒆𝒑𝒔 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒂 𝒏𝒐𝒏 − 𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏
𝒂𝒓𝒆 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<ul>

<h3>𝟏. 𝑰𝒈𝒏𝒐𝒓𝒆 𝒇(𝒏) 𝒂𝒏𝒅 𝒔𝒐𝒍𝒗𝒆 𝒕𝒉𝒆 𝒉𝒐𝒎𝒐𝒈𝒐𝒏𝒆𝒐𝒖𝒔 𝒑𝒂𝒓𝒕 𝒂𝒔𝒔𝒖𝒎𝒊𝒏𝒈
𝒕𝒉𝒂𝒕 𝒇(𝒏) = 𝟎.</h3>


<h3>𝟐.𝑹𝒆𝒔𝒕𝒐𝒓𝒆 𝒇(𝒏) 𝒂𝒏𝒅 𝒇𝒊𝒏𝒅 𝒂 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒏𝒐𝒏
−𝒉𝒐𝒎𝒐𝒈𝒆𝒏𝒐𝒖𝒔 𝒑𝒂𝒓𝒕 𝒕𝒉𝒂𝒕 𝒊𝒔 𝒓𝒆𝒘𝒓𝒊𝒕𝒕𝒆𝒏 𝒂𝒔
$(𝒓 − 𝒃)^{𝒅+𝟏}$ 𝒃𝒚 𝒊𝒈𝒏𝒐𝒓𝒊𝒏𝒈 𝒕𝒉𝒆 𝒃𝒐𝒖𝒏𝒅𝒂𝒓𝒚 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏𝒔.</h3>

<h3>𝟑. 𝑭𝒐𝒓𝒎 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒍 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒃𝒚 𝒄𝒐𝒏𝒔𝒊𝒅𝒆𝒓𝒊𝒏𝒈 𝒂𝒍𝒍 𝒕𝒉𝒆 𝒓𝒐𝒐𝒕𝒔
𝒐𝒃𝒕𝒂𝒊𝒏𝒆𝒅 𝒃𝒚 𝒑𝒆𝒓𝒇𝒐𝒓𝒎𝒊𝒏𝒈 𝒔𝒕𝒆𝒑𝒔 𝟏 𝒂𝒏𝒅 𝟐.</h3>

<h3>𝟒. 𝑼𝒔𝒆 𝒃𝒐𝒖𝒏𝒅𝒂𝒓𝒚 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏𝒔 𝒕𝒐 𝒅𝒆𝒕𝒆𝒓𝒎𝒊𝒏𝒆 𝒕𝒉𝒆 𝒔𝒑𝒆𝒄𝒊𝒇𝒊𝒄
𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒈𝒊𝒗𝒆𝒏 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>




</ul>


<h2></h2>
<h2>𝑬.𝑩.𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑵𝒐𝒏-𝑯𝒐𝒎𝒐𝒈𝒆𝒏𝒆𝒐𝒖𝒔 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏-𝑬𝒙𝒂𝒎𝒑𝒍𝒆</h2>

<ul>

<h3> $𝒕_𝒏$ − 𝟑 $𝒕_{𝒏−𝟏}$ = 𝒏 − 𝟏 , 𝒇𝒐𝒓 𝒏 = 𝟎, $𝒕_𝟎$ = 𝟎 , $𝒕_𝟏$ = 𝟏 ,  $𝒕_𝟐$ = 𝟐 → 
<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/E.B.2.Polynomial%20Reduction%20Method-Solving%20Non%20Homogeneous%20Equations-Example.pdf">  𝑬𝒙𝒂𝒎𝒑𝒍𝒆  </a></h3>

 
</ul>





</ul>



</ul>


<h2></h2>
<h2>𝑭.𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏</h2>

<ul>

<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏</ins></h3>

<ul>

<h3>𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 𝒊𝒔 𝒂𝒏𝒐𝒕𝒉𝒆𝒓 𝒘𝒂𝒚 𝒐𝒇 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒊𝒏𝒈
𝒕𝒉𝒆 𝒄𝒐𝒎𝒑𝒍𝒆𝒙𝒊𝒕𝒚 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 𝒐𝒇 𝒂𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎𝒔.</h3>
<h3>𝑻𝒉𝒊𝒔 𝒘𝒂𝒔 𝒊𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒆𝒅 𝒃𝒚 𝒕𝒉𝒆 𝒇𝒂𝒎𝒐𝒖𝒔 𝒎𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒊𝒂𝒏
𝑫𝒆 𝑴𝒐𝒊𝒓𝒆.</h3>
<h3>𝑨𝒃𝒓𝒂𝒉𝒂𝒎 𝑫𝒆 𝑴𝒐𝒊𝒓𝒆 𝒖𝒔𝒆𝒅 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 𝒕𝒐 𝒅𝒆𝒓𝒊𝒗𝒆
𝒕𝒉𝒆 𝑭𝒊𝒃𝒐𝒏𝒂𝒄𝒄𝒊 𝒏𝒖𝒎𝒃𝒆𝒓𝒔. 𝑳𝒆𝒐𝒏𝒂𝒓𝒅𝒐 𝑬𝒖𝒍𝒆𝒓 𝒖𝒔𝒆𝒅 𝒕𝒉𝒆𝒔𝒆 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔
𝒇𝒐𝒓 𝒑𝒂𝒓𝒕𝒊𝒕𝒊𝒐𝒏 𝒊𝒏𝒕𝒆𝒈𝒆𝒓𝒔; 𝑷𝒊𝒆𝒓𝒓𝒆 𝑺𝒊𝒎𝒐𝒏 𝑳𝒂𝒑𝒍𝒂𝒄𝒆 𝒖𝒔𝒆𝒅 𝒕𝒉𝒆𝒎
𝒆𝒙𝒕𝒆𝒏𝒔𝒊𝒗𝒆𝒍𝒚 𝒂𝒏𝒅 𝒊𝒏 𝟏𝟕𝟓𝟒 𝒑𝒖𝒃𝒍𝒊𝒔𝒉𝒆𝒅 𝒉𝒊𝒔 𝒘𝒐𝒓𝒌 𝒐𝒏 𝒕𝒉𝒆 𝒄𝒂𝒍𝒄𝒖𝒍𝒖𝒔
𝒐𝒇 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔. 𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 𝒉𝒂𝒗𝒆 𝒎𝒂𝒏𝒚
𝒂𝒑𝒑𝒍𝒊𝒄𝒂𝒕𝒊𝒐𝒏𝒔 𝒔𝒖𝒄𝒉 𝒂𝒔 𝒊𝒏 𝒄𝒐𝒖𝒏𝒕𝒊𝒏𝒈 𝒂𝒏𝒅 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔.</h3>
<h3>𝑻𝒉𝒆 𝒑𝒓𝒊𝒎𝒂𝒓𝒚 𝒖𝒔𝒆 𝒐𝒇 𝒂 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒊𝒔 𝒕𝒐 𝒔𝒐𝒍𝒗𝒆
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 , 𝒆𝒗𝒆𝒏 𝒘𝒉𝒆𝒏 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒔 𝒗𝒆𝒓𝒚
𝒄𝒐𝒎𝒑𝒍𝒆𝒙.</h3>
<h3>𝑭𝒐𝒓𝒎𝒂𝒍𝒍𝒚 , 𝒂 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒓𝒆𝒑𝒓𝒆𝒔𝒆𝒏𝒕𝒔 𝒂 𝒈𝒊𝒗𝒆𝒏
𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒂𝒔 𝒂 𝒑𝒐𝒘𝒆𝒓 𝒔𝒆𝒓𝒊𝒆𝒔.</h3>

<h3>𝑳𝒆𝒕 $𝒂_𝟎$, $𝒂_𝟏$, $𝒂_𝟐$, $𝒂_𝟑$, … , $𝒂_𝒏$ 𝒃𝒆 𝒇𝒊𝒏𝒊𝒕𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒐𝒇 𝒏𝒖𝒎𝒃𝒆𝒓𝒔, 𝒕𝒉𝒆
𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒄𝒂𝒏 𝒃𝒆 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒅 𝒂𝒔 𝒂 𝒑𝒐𝒘𝒆𝒓 𝒔𝒆𝒓𝒊𝒆𝒔
𝒊𝒏 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒘𝒂𝒚:</h3>

![Screenshot (844)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/2161af2b-ab65-46c4-8470-aec342130be1)

<h3>𝑯𝒆𝒓𝒆 `𝒛` 𝒊𝒔 𝒂𝒏 𝒊𝒏𝒕𝒆𝒓𝒎𝒊𝒅𝒊𝒂𝒕𝒆 𝒗𝒂𝒓𝒊𝒂𝒃𝒍𝒆 . 𝑻𝒉𝒆 𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎
𝒐𝒇 𝒕𝒉𝒊𝒔 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 𝒊𝒔 𝒈𝒊𝒗𝒆𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

![Screenshot (845)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/a1dfdb2e-40db-4960-bf19-9f74288b5dcb)

<h3>𝑳𝒆𝒕𝒔 𝒐𝒃𝒔𝒆𝒓𝒗𝒆 𝒔𝒐𝒎𝒆 𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎 𝒐𝒇 𝒔𝒐𝒎𝒆 𝒊𝒎𝒑𝒐𝒓𝒕𝒂𝒏𝒕
𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏:</h3>

<ul>
  

![Screenshot (853)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/3f07cfbb-ae88-4938-a0bd-6d055194eb03)

![Screenshot (854)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/35d8d449-d7f7-4e1a-95f5-07b25216e3bd)


</ul>


</ul>

<h2></h2>
<h2>𝑭.𝟏.𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏-𝑷𝒓𝒐𝒑𝒆𝒓𝒕𝒊𝒆𝒔</h2>

<ul>

<h3>𝑨𝒅𝒅𝒊𝒕𝒊𝒐𝒏 𝒂𝒏𝒅 𝑴𝒖𝒍𝒕𝒊𝒑𝒍𝒊𝒄𝒂𝒕𝒊𝒐𝒏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.1.Generating%20Function-%20Properties-Addition%20And%20Multiplication.pdf">  𝑷𝒓𝒐𝒑𝒆𝒓𝒕𝒚 </h3>

<h3>𝑺𝒉𝒊𝒇𝒕𝒊𝒏𝒈 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.2.Generating%20Function-Properties-Shifting.pdf">  𝑷𝒓𝒐𝒑𝒆𝒓𝒕𝒚 </h3>

  
</ul>

<h2></h2>
<h2>𝑭.𝟐.𝑺𝒕𝒆𝒑𝒔 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏</h2>

<ul>

<h3>𝑻𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒂𝒓𝒆 𝒕𝒉𝒆 𝒔𝒕𝒆𝒑𝒔 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏:</h3>
<h3>𝟏 → 𝑾𝒓𝒊𝒕𝒆 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒇𝒊𝒓𝒔𝒕.</h3>
<h3>𝟐 → 𝑪𝒐𝒏𝒗𝒆𝒓𝒕 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒏𝒕𝒐 𝒂 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈
𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏.</h3>
<h3>𝟑 → 𝑺𝒐𝒍𝒗𝒆 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒊𝒏 𝒕𝒆𝒓𝒎𝒔 𝒐𝒇
𝒑𝒂𝒓𝒕𝒊𝒂𝒍 𝒇𝒓𝒂𝒄𝒕𝒊𝒐𝒏𝒔.</h3>
<h3>𝟒 → 𝑫𝒆𝒓𝒊𝒗𝒆 𝒕𝒉𝒆 𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎 𝒐𝒇 𝑮(𝒛).</h3>
<h3>𝟓 → 𝑬𝒙𝒑𝒂𝒏𝒅 𝑮(𝒛) 𝒂𝒏𝒅 𝒕𝒉𝒆 𝒄𝒐𝒆𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕 𝒐𝒇 $𝒛^𝒏$ 𝒊𝒏 𝒕𝒉𝒆
𝒄𝒍𝒐𝒔𝒆𝒅 𝒇𝒐𝒓𝒎 𝒊𝒔 𝒕𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
  
</ul>

<h2></h2>
<h2>𝑭.𝟑.𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 −𝑷𝒂𝒓𝒕𝒊𝒂𝒍 𝑭𝒓𝒂𝒄𝒕𝒊𝒐𝒏.</h2>

<ul>

<h3>𝑴𝒂𝒏𝒚 𝒂 𝒕𝒊𝒎𝒆𝒔 𝒂 𝒑𝒂𝒓𝒕𝒊𝒂𝒍 𝒇𝒓𝒂𝒄𝒕𝒊𝒐𝒏 𝒉𝒂𝒔 𝒕𝒐 𝒃𝒆 𝒇𝒐𝒖𝒏𝒅 𝒇𝒐𝒓 𝒂
𝒈𝒊𝒗𝒆𝒏 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒕𝒐 𝒔𝒐𝒍𝒗𝒆 𝒂 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>

<h3>𝑾𝒉𝒂𝒕 𝒊𝒔 𝒂 𝒑𝒂𝒓𝒕𝒊𝒂𝒍 𝒇𝒓𝒂𝒄𝒕𝒊𝒐𝒏?</h3>

<h3>𝑨 𝒑𝒂𝒓𝒕𝒊𝒂𝒍 𝒇𝒓𝒂𝒄𝒕𝒊𝒐𝒏 𝒊𝒔 𝒂 𝒘𝒂𝒚 𝒕𝒐 𝒅𝒆𝒄𝒐𝒎𝒑𝒐𝒔𝒆 𝒂 𝒇𝒓𝒂𝒄𝒕𝒊𝒐𝒏 𝒊𝒏𝒕𝒐
𝒑𝒂𝒓𝒕𝒔 𝒕𝒉𝒂𝒕 𝒄𝒂𝒏 𝒃𝒆 𝒔𝒐𝒍𝒗𝒆𝒅 𝒆𝒂𝒔𝒊𝒍𝒚.</h3>

<h2></h2>
<h2>𝑭.𝟒.𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 −𝑷𝒂𝒓𝒕𝒊𝒂𝒍 𝑭𝒓𝒂𝒄𝒕𝒊𝒐𝒏𝒔 −𝑬𝒙𝒂𝒎𝒑𝒍𝒆</h2>

<ul>

<h3>𝑷𝒂𝒓𝒕𝒊𝒂𝒍 𝑭𝒓𝒂𝒄𝒕𝒊𝒐𝒏𝒔→ <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.A.Generating%20Function-Partial%20Fraction-Example..pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 </h3>


</ul>

</ul>

<h2></h2>
<h2>𝑭.𝑩.𝑮𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝑭𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 −𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔</h2>

<ul>
  
<h3>𝑭𝒊𝒏𝒅 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒔𝒆𝒒𝒖𝒆𝒏𝒄𝒆 $𝒂_𝒏$ = {𝟒, 𝟏𝟔, 𝟔𝟒, … } → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.B.1.Generating%20Function-Example-1.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </h3>

<h3>$𝒕_𝒏$ = 𝟓 $𝒕_{𝒏−𝟏}$ 𝒇𝒐𝒓 𝒏 = 𝟏, 𝟐, 𝟑, … ; $𝒕_𝟎$ = 𝟐 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.B.2.Generating%20Function-Example-2.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </h3> 


<h3>$𝒕_𝒏$ - 𝟐 $𝒕_{𝒏−𝟏}$ = 𝟏  ; $𝒕_𝟎$ = 𝟎 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/F.B.3.Generating%20Function-Example-3.pdf"> 𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟑 </h3>

</ul>

<h3>𝑻𝒉𝒖𝒔 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏𝒔 𝒂𝒓𝒆 𝒖𝒔𝒆𝒇𝒖𝒍 𝒊𝒏 𝒇𝒊𝒏𝒅𝒊𝒏𝒈 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏𝒔 
𝒐𝒇 𝒎𝒂𝒏𝒚 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔. </h3>
 
<h3>𝑬𝒗𝒆𝒏 𝒊𝒇 𝒕𝒉𝒆 𝒏𝒐𝒓𝒎𝒂𝒍 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒇𝒂𝒊𝒍 , 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒕𝒊𝒏𝒈 𝒇𝒖𝒏𝒄𝒕𝒊𝒐𝒏 
𝒎𝒆𝒕𝒉𝒐𝒅 𝒄𝒂𝒏 𝒃𝒆 𝒓𝒆𝒍𝒊𝒆𝒅 𝒖𝒑𝒐𝒏. </h3>

</ul>

</ul>

</ul>

<h2></h2>
<h2>𝑩.𝑩.𝑺𝒐𝒍𝒗𝒊𝒏𝒈 𝑵𝒐𝒏-𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔-𝑫𝒊𝒗𝒊𝒅𝒆 𝒂𝒏𝒅 𝑪𝒐𝒏𝒒𝒖𝒆𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔</h2>

<ul>

<h3><ins>𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏:</ins></h3>

<ul>

<h3>𝑻𝒉𝒊𝒔 𝒔𝒆𝒄𝒕𝒊𝒐𝒏 𝒓𝒆𝒗𝒊𝒆𝒘𝒔 𝒔𝒐𝒎𝒆 𝒐𝒇 𝒕𝒉𝒆 𝒕𝒆𝒄𝒉𝒏𝒊𝒒𝒖𝒆𝒔 𝒔𝒑𝒆𝒄𝒊𝒇𝒊𝒄𝒂𝒍𝒍𝒚
𝒖𝒔𝒆𝒅 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒅𝒊𝒗𝒊𝒅𝒆 𝒂𝒏𝒅 𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏𝒔.</h3>
<h3>𝑹𝒆𝒄𝒐𝒍𝒍𝒆𝒄𝒕 𝒕𝒉𝒂𝒕 𝒊𝒏 𝒂 𝒏𝒐𝒏 − 𝒍𝒊𝒏𝒆𝒂𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏
𝒕𝒉𝒆 𝒏𝒕𝒉 𝒕𝒆𝒓𝒎 𝒊𝒔 𝒆𝒙𝒑𝒓𝒆𝒔𝒔𝒆𝒅 𝒂𝒔 𝒂 𝒏𝒐𝒏 − 𝒍𝒊𝒏𝒆𝒂𝒓 𝒄𝒐𝒎𝒃𝒊𝒏𝒂𝒕𝒊𝒐𝒏
𝒐𝒇 𝒊𝒕𝒔 𝒑𝒓𝒆𝒗𝒊𝒐𝒖𝒔 𝒕𝒆𝒓𝒎𝒔 .</h3>
<h3>∗∗∗∗∗ 𝑻𝒉𝒆 𝒎𝒆𝒕𝒉𝒐𝒅𝒔 𝒅𝒊𝒔𝒄𝒖𝒔𝒔𝒆𝒅 𝒆𝒂𝒓𝒍𝒊𝒆𝒓,
𝒔𝒖𝒄𝒉 𝒂𝒔 : <ins>𝒈𝒖𝒆𝒔𝒔 𝒂𝒏𝒅 𝒗𝒆𝒓𝒊𝒇𝒚</ins> , <ins>𝒔𝒖𝒃𝒔𝒕𝒊𝒕𝒖𝒕𝒊𝒐𝒏</ins> , 𝒂𝒏𝒅 <ins>𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒕𝒓𝒆𝒆</ins>
𝒄𝒂𝒏 𝒃𝒆 𝒖𝒔𝒆𝒅 𝒕𝒐 𝒔𝒐𝒍𝒗𝒆 𝒅𝒊𝒗𝒊𝒅𝒆 𝒂𝒏𝒅 𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆
𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏. ∗∗∗∗∗∗∗</h3>

<h3>𝑨𝒑𝒂𝒓𝒕 𝒇𝒓𝒐𝒎 𝒕𝒉𝒊𝒔 𝒂𝒏𝒐𝒕𝒉𝒆𝒓 𝒎𝒆𝒕𝒉𝒐𝒅 𝒆𝒙𝒊𝒔𝒕𝒔 , 𝒘𝒉𝒊𝒄𝒉 𝒄𝒂𝒏 𝒅𝒊𝒓𝒆𝒄𝒕𝒍𝒚 
𝒑𝒓𝒐𝒅𝒖𝒄𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏𝒔. 𝑰𝒕 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒕𝒉𝒆 <ins>𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒐𝒓 
𝒕𝒂𝒃𝒍𝒆 𝒍𝒐𝒐𝒌 − 𝒖𝒑 𝒎𝒆𝒕𝒉𝒐𝒅. </ins></h3>

</ul>

<h2></h2>
<h2>𝑰)𝑺𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 </h2>

<ul>

<h3>𝑻𝒉𝒆 𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒊𝒔 𝒖𝒔𝒆𝒅 𝒇𝒐𝒓 𝒔𝒐𝒍𝒗𝒊𝒏𝒈 𝒅𝒊𝒗𝒊𝒅𝒆 − 𝒂𝒏𝒅 −
𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒓𝒆𝒍𝒂𝒕𝒊𝒐𝒏𝒔.</h3>
<h3>𝑾𝒉𝒊𝒍𝒆 𝒕𝒉𝒆 𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒅𝒐𝒆𝒔𝒏𝒐𝒕 𝒔𝒐𝒍𝒗𝒆 𝒂𝒍𝒍 𝒕𝒚𝒑𝒆𝒔 𝒐𝒇
𝒅𝒊𝒗𝒊𝒅𝒆 − 𝒂𝒏𝒅 − 𝒄𝒐𝒏𝒒𝒖𝒆𝒓 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆𝒔 ,𝒊𝒕 𝒄𝒂𝒏 𝒔𝒐𝒍𝒗𝒆 𝒕𝒉𝒆
𝒎𝒂𝒋𝒐𝒓𝒊𝒕𝒚 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝑨𝒕 𝒑𝒓𝒆𝒍𝒊𝒎𝒊𝒏𝒂𝒓𝒚 𝒔𝒕𝒂𝒈𝒆 , 𝒘𝒆 𝒂𝒓𝒆 𝒑𝒓𝒐𝒗𝒊𝒅𝒆𝒅 𝒘𝒊𝒕𝒉 𝒕𝒉𝒆 𝒇𝒐𝒓𝒎𝒖𝒍𝒂:</h3>

<h3>𝑻(𝒏) = 𝒂𝑻 ( $\frac{𝒏}{𝒃}$ ) + 𝐜 $𝐧^𝐤$ .</h3>

<h3>𝑻(𝟏) = 𝒅</h3>

<h3>𝑯𝒆𝒓𝒆 𝒂, 𝒅, 𝒃, 𝒌 𝒂𝒓𝒆 𝒂𝒍𝒍 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒔 .</h3>
<h3>𝑯𝒆𝒓𝒆 𝒃 ≥ 𝟐, 𝒌 ≥ 𝟎, 𝒂 > 𝟎, 𝒄 > 𝟎 𝒂𝒏𝒅 𝒅 ≥ 𝟎. 𝑻𝒉𝒆 𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏
𝒇𝒐𝒓 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏 𝒊𝒔 𝒈𝒊𝒗𝒆𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<ul>
  
<h3>𝑪𝒂𝒔𝒆 𝟏: 𝑻(𝒏) ∈ 𝚯( $𝒏^𝒌$ ) 𝒊𝒇 𝒂 < $𝒃^k$</h3>
<h3>𝑪𝒂𝒔𝒆 𝟐: 𝑻(𝒏) ∈ 𝚯( $𝒏^𝒌$  𝐥𝐨𝐠 𝒏) 𝒊𝒇 𝒂 = $𝒃^𝒌$</h3>

<h3>𝑪𝒂𝒔𝒆 𝟑: 𝑻(𝒏) ∈ 𝚯( $𝒏^{𝐥𝐨𝐠_𝒃(𝒂)}$ ) 𝒊𝒇 𝒂 > $𝒃^𝒌$</h3>

<h3> → → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.1.Divide-And-Conquer%20Recurrences-Simplified%20MasterTheorem.pdf"> 𝑺𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 - (𝑽𝒊𝒗𝒊𝒅𝒍𝒚 𝒆𝒙𝒑𝒍𝒂𝒊𝒏𝒆𝒅) 𝑷𝒓𝒐𝒐𝒇 𝑨𝒏𝒅 𝑬𝒙𝒑𝒍𝒂𝒏𝒂𝒕𝒊𝒐𝒏. [**𝑷𝒓𝒐𝒐𝒇 𝑼𝒑𝒅𝒂𝒕𝒆𝒅** 𝒂𝒏𝒅 **𝑨𝒄𝒄𝒖𝒓𝒂𝒕𝒆**] </a></h3>

<ul>

<h2></h2>
<h2>𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔 𝑩𝒂𝒔𝒆𝒅 𝑶𝒏 𝑺𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3>𝟏. 𝑻(𝒏) = 𝟖𝑻 ( $\frac{𝒏}{𝟐}$ ) + $𝒏^𝟐$ →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.2.Divide-And-Conquer-Simplified-Master-Theorem-Example-1.pdf"> 𝑺𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 -𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </h3>

<h3>𝟐. 𝑻(𝒏) = 𝟐𝑻 ( $\frac{𝒏}{𝟐}$ ) + 𝒏 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.3.Divide-And-Conquer-Simplified-Master-Theorem-Example-2.pdf"> 𝑺𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 -𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </h3>



  
</ul>


 
</ul>


</ul>

<h2></h2>
<h2>𝑰𝑰)𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑰𝒏𝒆𝒒𝒖𝒂𝒍𝒊𝒕𝒊𝒆𝒔</h2>

<ul>

<h3>𝑻𝒉𝒆 𝒔𝒊𝒎𝒑𝒍𝒊𝒇𝒊𝒆𝒅 𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒄𝒂𝒏 𝒂𝒍𝒔𝒐 𝒃𝒆 𝒆𝒙𝒕𝒆𝒏𝒅𝒆𝒅 𝒇𝒐𝒓
𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒏𝒆𝒒𝒖𝒂𝒍𝒊𝒕𝒊𝒆𝒔 . 𝑺𝒐𝒎𝒆𝒕𝒊𝒎𝒆𝒔 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒆𝒒𝒖𝒂𝒕𝒊𝒐𝒏
𝒊𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒇𝒐𝒓𝒎:</h3>

<h3 align="Center">𝑻(𝒏) ≤ 𝟐𝑻 ( $\frac{𝒏}{𝟐}$ ) + 𝒄𝒏 </h3>

<h3>𝑻𝒉𝒊𝒔 𝒌𝒊𝒏𝒅 𝒐𝒇 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒔 𝒄𝒂𝒍𝒍𝒆𝒅 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒏𝒆𝒒𝒖𝒂𝒍𝒊𝒕𝒚. 𝑻𝒉𝒆
𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 𝒄𝒂𝒏 𝒃𝒆 𝒖𝒔𝒆𝒅 𝒕𝒐 𝒔𝒐𝒍𝒗𝒆 𝒕𝒉𝒊𝒔 𝒊𝒏𝒆𝒒𝒖𝒂𝒍𝒊𝒕𝒚.</h3>

<h3>𝑻𝒉𝒖𝒔 𝒊𝒇 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒄𝒂𝒏 𝒃𝒆 𝒘𝒓𝒊𝒕𝒕𝒆𝒏 𝒊𝒏 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈
𝒇𝒐𝒓𝒎:</h3>

<h3 align="Center">𝑻(𝒏) ≤ 𝒂𝑻 ( $\frac{𝒏}{𝒃}$ ) + 𝒄 $𝒏^𝒌$ </h3>

<h3>𝒕𝒉𝒆𝒏 𝒐𝒏𝒆 𝒄𝒂𝒏 𝒖𝒔𝒆 𝒕𝒉𝒆 𝒃𝒊𝒈 − 𝒐𝒉 (𝑶)𝒏𝒐𝒕𝒂𝒕𝒊𝒐𝒏.</h3>
<h3>𝑺𝒊𝒎𝒊𝒍𝒂𝒓𝒍𝒚,𝒊𝒇 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝒊𝒔 𝒐𝒇 𝒕𝒉𝒆 𝒇𝒐𝒍𝒍𝒐𝒘𝒊𝒏𝒈 𝒇𝒐𝒓𝒎:</h3>

<h3 align="Center">𝑻(𝒏) ≥ 𝒂𝑻 ( $\frac{𝒏}{𝒃}$ ) + 𝒄 $𝒏^𝒌$ </h3>

<h3>𝑻𝒉𝒆𝒏 𝚯 𝒄𝒂𝒏 𝒃𝒆 𝒓𝒆𝒑𝒍𝒂𝒄𝒆𝒅 𝒃𝒚 𝛀 .</h3>
<h3>𝑻𝒉𝒆 𝒔𝒂𝒎𝒆 𝒍𝒐𝒈𝒊𝒄 𝒄𝒂𝒏 𝒃𝒆 𝒆𝒙𝒕𝒆𝒏𝒅𝒆𝒅 𝒕𝒐 𝒐𝒕𝒉𝒆𝒓 𝒏𝒐𝒕𝒂𝒕𝒊𝒐𝒏𝒔
𝒂𝒔 𝒘𝒆𝒍𝒍.</h3>

</ul>


<h2></h2>
<h2>𝑰𝑰𝑰)𝑨𝒌𝒓𝒂 − 𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3>𝑰𝒏 𝟏𝟗𝟗𝟖 , 𝒕𝒘𝒐 𝑳𝒆𝒃𝒂𝒏𝒐𝒏 − 𝒃𝒂𝒔𝒆𝒅 𝒓𝒆𝒔𝒆𝒂𝒓𝒄𝒉𝒆𝒓𝒔 𝒑𝒓𝒐𝒗𝒊𝒅𝒆𝒅 𝒕𝒉𝒆
𝒔𝒐𝒍𝒖𝒕𝒊𝒐𝒏𝒔 𝒇𝒐𝒓 𝒕𝒉𝒆 𝒈𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝒇𝒐𝒓𝒎 𝒐𝒇 𝒕𝒉𝒆 𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎,
𝒘𝒉𝒊𝒄𝒉 𝒊𝒔 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

![Screenshot (861)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/fbee4eda-ee93-438d-a117-b5b5f47daf4a)

<h3>𝑾𝒉𝒊𝒄𝒉 𝒓𝒆𝒔𝒖𝒍𝒕𝒔 𝒊𝒏:</h3>

![Screenshot (863)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/771ebe80-3578-48fa-b625-9faac5760d30)



<ul>
  
<h3> 𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎-𝑰𝒏 𝑫𝒆𝒕𝒂𝒊𝒍𝒔 → <a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.5.Divide-And-Conquer-Akra-Bazzi-Theorem.pdf">𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</a></h3>
  
</ul>

<ul>


<h2></h2>
<h2>𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔 𝑩𝒂𝒔𝒆𝒅 𝑶𝒏 𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>



<h3>𝟏. 𝑻(𝒏) = 𝟑𝑻 ( $\frac{𝒏}{𝟑}$ ) + 𝒏 →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.6.Divide-And-Conquer-Akra-Bazzi-Theorem-Example-1.pdf"> 𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 -𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </h3>

<h3>𝟐. 𝑻(𝒏) = 𝟖𝑻 ( $\frac{𝒏}{𝟐}$ ) + $𝒏^𝟐$ →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.7.Divide-And-Conquer-Akra-Bazzi-Theorem-Example-2.pdf"> 𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎-𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </h3>

</ul>

<h2></h2>
<h2>𝑴𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒂𝒍 𝑷𝒓𝒐𝒐𝒇 𝒐𝒇 𝑨𝒌𝒃𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3>𝑻𝒉𝒆 𝒑𝒓𝒐𝒐𝒇 𝒊𝒔 𝒈𝒊𝒗𝒆𝒏 𝒃𝒚 𝑴𝒐𝒉𝒂𝒎𝒎𝒂𝒅 𝑨𝒌𝒓𝒂 𝒂𝒏𝒅 𝑳𝑶𝑼𝑨𝒀 𝑩𝑨𝒁𝒁𝑰
𝒊𝒏 𝑶𝒏 𝒕𝒉𝒆 𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔 .</h3>

<h3>𝑩𝒆𝒍𝒐𝒘 𝒊𝒔 𝒓𝒆-𝒘𝒓𝒊𝒕𝒕𝒆𝒏 𝒑𝒓𝒐𝒐𝒇 𝒇𝒓𝒐𝒎 𝒕𝒉𝒆 "𝑶𝒏 𝒕𝒉𝒆 𝑺𝒐𝒍𝒖𝒕𝒊𝒐𝒏 𝒐𝒇 𝑳𝒊𝒏𝒆𝒂𝒓 𝑹𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆 𝑬𝒒𝒖𝒂𝒕𝒊𝒐𝒏𝒔" 𝒘𝒊𝒕𝒉 𝒆𝒍𝒂𝒃𝒐𝒓𝒂𝒕𝒆𝒅 𝒔𝒕𝒆𝒑𝒔 𝒂𝒏𝒅 𝒖𝒏𝒅𝒆𝒓𝒔𝒕𝒂𝒏𝒅𝒊𝒏𝒈𝒔.</h3>

<ul>
<h3><a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.8.Divide-And-Conquer-Proof%20Of%20Akrabazzi%20Theorem.pdf"> 𝑨𝒌𝒓𝒂 -𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 -𝑷𝒓𝒐𝒐𝒇  </h3>

</ul>


</ul>

<h3>𝑨𝒏𝒅 𝒇𝒓𝒐𝒎 𝑨𝒌𝒓𝒂-𝑩𝒂𝒛𝒛𝒊 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 , 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑽𝒆𝒓𝒔𝒊𝒐𝒏 𝒐𝒇 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 𝒉𝒂𝒗𝒆 𝒃𝒆𝒆𝒏 𝒆𝒔𝒕𝒂𝒃𝒍𝒊𝒔𝒉𝒆𝒅 .</h3>
  
</ul>




  
</ul>

<h2></h2>
<h2>𝑰𝑽)𝑪𝒐𝒏𝒕𝒊𝒏𝒖𝒐𝒖𝒔 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 𝒐𝒓 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3>𝑨 𝒈𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝒗𝒆𝒓𝒔𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝑨𝒌𝒓𝒂 − 𝑩𝒂𝒛𝒛𝒊 𝒕𝒉𝒆𝒐𝒓𝒆𝒎
𝒉𝒂𝒔 𝒃𝒆𝒆𝒏 𝒈𝒊𝒗𝒆𝒏 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

![Screenshot (866)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/7b135049-c8f1-42b9-8925-ec9c9ab2a625)


<h3>𝒂𝒏𝒅 𝒂 ≥ 𝟏, 𝒃 > 𝟏, 𝒏𝟎 ≥ 𝟏, 𝒅 > 𝟎 𝒂𝒏𝒅 𝒇(𝒏) 𝒊𝒔 𝒑𝒐𝒔𝒊𝒕𝒊𝒗𝒆 𝒇𝒐𝒓
𝒏 > 𝒏𝟎 , 𝒐𝒓</h3>

<h3>𝑳𝒆𝒕 𝒂 > 𝟎 𝒂𝒏𝒅 𝒃 > 𝟏 𝒃𝒆 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕𝒔, 𝒂𝒏𝒅 𝒍𝒆𝒕 𝒏𝒖𝒎𝒃𝒆𝒓𝒔 𝒏 ≥ 𝟏.
𝑻𝒉𝒆𝒏 𝒕𝒉𝒆 𝒓𝒆𝒄𝒖𝒓𝒓𝒆𝒏𝒄𝒆:</h3>

![Screenshot (867)](https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/assets/38869235/b896e4bf-097e-4790-ba1a-5aef86ba8ea4)


<h3>𝑻𝒉𝒆𝒏 𝒕𝒉𝒆 𝒂𝒔𝒚𝒎𝒑𝒕𝒐𝒕𝒊𝒄 𝒃𝒆𝒉𝒂𝒗𝒊𝒐𝒓 𝒐𝒇 𝑻(𝒏) 𝒄𝒂𝒏 𝒃𝒆
𝒄𝒉𝒂𝒓𝒂𝒄𝒕𝒆𝒓𝒊𝒛𝒆𝒅 𝒂𝒔 𝒇𝒐𝒍𝒍𝒐𝒘𝒔:</h3>

<ul>
  
<h3>𝟏. 𝑰𝒇 𝒕𝒉𝒆𝒓𝒆 𝒆𝒙𝒊𝒔𝒕𝒔 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝜺 > 𝟎 𝒔𝒖𝒄𝒉 𝒕𝒉𝒂𝒕
𝒇(𝒏) = 𝑶( $𝒏^{𝒍𝒐𝒈_𝒃^{𝒂−𝜺}}$ ), 𝒕𝒉𝒆𝒏 𝑻(𝒏) = 𝚯( $𝒏^{𝒍𝒐𝒈_𝒃^𝒂}$).</h3>

<h3>𝟐. 𝑰𝒇 𝒕𝒉𝒆𝒓𝒆 𝒆𝒙𝒊𝒔𝒕𝒔 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒌 ≥ 𝟎 𝒔𝒖𝒄𝒉 𝒕𝒉𝒂𝒕
𝒇(𝒏) = 𝚯( $𝒏^{𝒍𝒐𝒈_𝒃^𝒂}$ $𝒍𝒐𝒈^𝒌$ 𝒏) , 𝒕𝒉𝒆𝒏 𝑻(𝒏) = 𝚯( $𝒏^{𝒍𝒐𝒈_𝒃^𝒂}$ $𝒍𝒐𝒈^{𝒌+1}$ 𝒏 ).</h3>

<h3>𝟑. 𝑰𝒇 𝒕𝒉𝒆𝒓𝒆 𝒆𝒙𝒊𝒔𝒕𝒔 𝒂 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝜺 > 𝟎 𝒔𝒖𝒄𝒉 𝒕𝒉𝒂𝒕
𝒇(𝒏) = 𝛀( $𝒏^{𝒍𝒐𝒈_𝒃^{𝒂+𝜺}}$ ) , 𝒂𝒏𝒅 𝒊𝒇 𝒇(𝒏) 𝒂𝒅𝒅𝒊𝒕𝒊𝒐𝒏𝒂𝒍𝒍𝒚 𝒔𝒂𝒕𝒊𝒔𝒇𝒊𝒆𝒔 𝒕𝒉𝒆 𝒓𝒆𝒈𝒖𝒍𝒂𝒓𝒊𝒕𝒚 𝒄𝒐𝒏𝒅𝒊𝒕𝒊𝒐𝒏 𝒂𝒇 ( $\frac{𝒏}{𝒃}$ ) ≤ 𝒄𝒇(𝒏) 𝒇𝒐𝒓 𝒔𝒐𝒎𝒆 𝒄𝒐𝒏𝒔𝒕𝒂𝒏𝒕 𝒄 < 𝟏 𝒂𝒏𝒅
𝒂𝒍𝒍 𝒔𝒖𝒇𝒇𝒊𝒄𝒊𝒆𝒏𝒕𝒍𝒚 𝒍𝒂𝒓𝒈𝒆 𝒏, 𝒕𝒉𝒆𝒏 𝑻(𝒏) = 𝚯(𝒇(𝒏)).</h3>

<ul>

<h3>→<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.9.Divide-And-Conquer-Continuous%20Master%20Theorem%20OR%20Generalized%20Master%20Theorem%20-Introduction.pdf"> 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 → 𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏 </a> </h3>

</ul>

</ul>


<h2></h2>
<h2>𝑴𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒂𝒍 𝑷𝒓𝒐𝒐𝒇 𝒐𝒇 𝑪𝒐𝒏𝒕𝒊𝒏𝒖𝒐𝒖𝒔 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 𝒐𝒓 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>

<h3>𝑨 𝒈𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝒗𝒆𝒓𝒔𝒊𝒐𝒏 𝒐𝒇 𝒕𝒉𝒆 𝑨𝒌𝒓𝒂 − 𝑩𝒂𝒛𝒛𝒊 𝒕𝒉𝒆𝒐𝒓𝒆𝒎 
𝒉𝒂𝒔 𝒃𝒆𝒆𝒏 𝒈𝒊𝒗𝒆𝒏 𝒃𝒚 𝑪𝒐𝒓𝒎𝒆𝒏 𝒊𝒏 𝒉𝒊𝒔 𝒃𝒐𝒐𝒌 "𝑰𝒏𝒕𝒓𝒐𝒅𝒖𝒄𝒕𝒊𝒐𝒏 𝒕𝒐
𝑨𝒍𝒈𝒐𝒓𝒊𝒕𝒉𝒎"𝒔. 𝑻𝒉𝒆 𝒂𝒅𝒗𝒂𝒏𝒕𝒂𝒈𝒆 𝒐𝒇 𝒕𝒉𝒊𝒔 𝒎𝒐𝒅𝒊𝒇𝒊𝒆𝒅 𝒎𝒂𝒔𝒕𝒆𝒓 𝒕𝒉𝒆𝒐𝒓𝒆𝒎
𝒊𝒔 𝒕𝒉𝒂𝒕 𝒊𝒕 𝒂𝒗𝒐𝒊𝒅𝒔 𝒕𝒉𝒆 𝒊𝒏𝒕𝒆𝒈𝒓𝒂𝒕𝒊𝒐𝒏 𝒓𝒆𝒒𝒖𝒊𝒓𝒆𝒅 𝒊𝒏 𝒕𝒉𝒆 
𝑨𝒌𝒓𝒂 − 𝑩𝒂𝒛𝒛𝒊 𝒎𝒆𝒕𝒉𝒐𝒅. </h3>

<ul>

<h3> →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.10.Divide-And-Conquer-Continuous%20Master%20Theorem%20OR%20Generalized%20Master%20Theorem%20-Proof.pdf"> 𝑴𝒂𝒕𝒉𝒆𝒎𝒂𝒕𝒊𝒄𝒂𝒍 𝑷𝒓𝒐𝒐𝒇 𝒐𝒇 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 </a></h3>

</ul>

<h2></h2>
<h2>𝑬𝒙𝒂𝒎𝒑𝒍𝒆𝒔 𝑩𝒂𝒔𝒆𝒅 𝑶𝒏  𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎</h2>

<ul>



<h3>𝟏. 𝑻(𝒏) = 𝟖𝑻 ( $\frac{𝒏}{𝟐}$ ) + $𝒏^𝟐$  →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.11.Divide-And-Conquer-Continuous%20Master%20Theorem%20OR%20Generalized%20Master%20Theorem%20-Example%201.pdf"> 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎 -𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟏 </h3>

<h3>𝟐. 𝑻(𝒏) = 𝟐𝑻 ( $\frac{𝒏}{𝟐}$ ) + 𝒏  →<a href="https://github.com/AvinandanBose/Time_Complexity_Calculation_Of_Recursion/blob/main/B.B.12.Divide-And-Conquer-Continuous%20Master%20Theorem%20OR%20Generalized%20Master%20Theorem%20-Example%202.pdf"> 𝑮𝒆𝒏𝒆𝒓𝒂𝒍𝒊𝒛𝒆𝒅 𝑴𝒂𝒔𝒕𝒆𝒓 𝑻𝒉𝒆𝒐𝒓𝒆𝒎-𝑬𝒙𝒂𝒎𝒑𝒍𝒆 𝟐 </h3>


</ul>


  
</ul>


  
</ul>


</ul>
</ul>




</ul>
